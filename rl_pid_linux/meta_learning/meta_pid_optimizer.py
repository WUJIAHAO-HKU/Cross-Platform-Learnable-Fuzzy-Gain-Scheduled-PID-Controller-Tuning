"""
å…ƒå­¦ä¹ PIDä¼˜åŒ–å™¨

åŠŸèƒ½ï¼š
1. ä»æœºå™¨äººURDFæå–ç‰¹å¾ï¼ˆDOF, è´¨é‡, æƒ¯é‡, é•¿åº¦ç­‰ï¼‰
2. ä½¿ç”¨ç¥ç»ç½‘ç»œé¢„æµ‹æœ€ä¼˜PIDå‚æ•°
3. å®ç°é›¶æ ·æœ¬è¿ç§»åˆ°æ–°æœºå™¨äºº
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pybullet as p
import pybullet_data
import yaml
from pathlib import Path


class RobotFeatureExtractor:
    """ä»URDFæå–æœºå™¨äººç‰¹å¾"""
    
    def __init__(self):
        self.feature_names = [
            'dof',
            'total_mass',
            'avg_link_mass',
            'max_link_mass',
            'total_inertia',
            'max_reach',
            'avg_link_length',
            'max_link_length',
            'payload_mass',
            'payload_distance'
        ]
    
    def extract_features(self, urdf_path, payload=0.0, use_gui=False):
        """
        ä»URDFæå–ç‰¹å¾
        
        Args:
            urdf_path: URDFæ–‡ä»¶è·¯å¾„
            payload: æœ«ç«¯è´Ÿè½½è´¨é‡(kg)
            use_gui: æ˜¯å¦æ˜¾ç¤ºGUIï¼ˆè°ƒè¯•ç”¨ï¼‰
        
        Returns:
            dict: ç‰¹å¾å­—å…¸
        """
        # è¿æ¥PyBullet
        if use_gui:
            client = p.connect(p.GUI)
        else:
            client = p.connect(p.DIRECT)
        
        p.setAdditionalSearchPath(pybullet_data.getDataPath(), physicsClientId=client)
        
        try:
            # åŠ è½½æœºå™¨äºº
            robot_id = p.loadURDF(str(urdf_path), [0, 0, 0], physicsClientId=client)
            
            # è·å–å…³èŠ‚ä¿¡æ¯
            num_joints = p.getNumJoints(robot_id, physicsClientId=client)
            
            # åªè€ƒè™‘å¯æ§åˆ¶å…³èŠ‚ï¼ˆæ—‹è½¬å…³èŠ‚ï¼‰
            controllable_joints = []
            joint_masses = []
            joint_inertias = []
            link_lengths = []
            
            for i in range(num_joints):
                joint_info = p.getJointInfo(robot_id, i, physicsClientId=client)
                joint_type = joint_info[2]
                
                # åªè€ƒè™‘æ—‹è½¬å…³èŠ‚å’Œç§»åŠ¨å…³èŠ‚
                if joint_type in [p.JOINT_REVOLUTE, p.JOINT_PRISMATIC]:
                    controllable_joints.append(i)
                    
                    # è·å–åŠ¨åŠ›å­¦å‚æ•°
                    dynamics_info = p.getDynamicsInfo(robot_id, i, physicsClientId=client)
                    mass = dynamics_info[0]
                    inertia = dynamics_info[2]  # å±€éƒ¨æƒ¯é‡å¯¹è§’çº¿
                    
                    joint_masses.append(mass)
                    joint_inertias.append(sum(inertia))  # æƒ¯é‡å’Œ
                    
                    # è®¡ç®—è¿æ†é•¿åº¦ï¼ˆé€šè¿‡å…³èŠ‚ä½ç½®ï¼‰
                    joint_state = p.getLinkState(robot_id, i, physicsClientId=client)
                    link_pos = joint_state[0]
                    link_length = np.linalg.norm(link_pos)
                    link_lengths.append(link_length)
            
            # è®¡ç®—ç‰¹å¾
            dof = len(controllable_joints)
            total_mass = sum(joint_masses)
            avg_link_mass = np.mean(joint_masses) if joint_masses else 0
            max_link_mass = max(joint_masses) if joint_masses else 0
            total_inertia = sum(joint_inertias)
            
            # è®¡ç®—æœ€å¤§åˆ°è¾¾è·ç¦»ï¼ˆç´¯ç§¯è¿æ†é•¿åº¦ï¼‰
            cumulative_lengths = np.cumsum(link_lengths)
            max_reach = cumulative_lengths[-1] if len(cumulative_lengths) > 0 else 0
            avg_link_length = np.mean(link_lengths) if link_lengths else 0
            max_link_length = max(link_lengths) if link_lengths else 0
            
            # æœ«ç«¯æ‰§è¡Œå™¨ä¿¡æ¯
            if dof > 0:
                end_effector_state = p.getLinkState(robot_id, controllable_joints[-1], 
                                                   physicsClientId=client)
                payload_distance = np.linalg.norm(end_effector_state[0])
            else:
                payload_distance = 0
            
            features = {
                'dof': dof,
                'total_mass': total_mass,
                'avg_link_mass': avg_link_mass,
                'max_link_mass': max_link_mass,
                'total_inertia': total_inertia,
                'max_reach': max_reach,
                'avg_link_length': avg_link_length,
                'max_link_length': max_link_length,
                'payload_mass': payload,
                'payload_distance': payload_distance
            }
            
            return features, controllable_joints
        
        finally:
            p.disconnect(physicsClientId=client)
    
    def normalize_features(self, features, stats=None):
        """
        å½’ä¸€åŒ–ç‰¹å¾
        
        Args:
            features: ç‰¹å¾å­—å…¸
            stats: å½’ä¸€åŒ–ç»Ÿè®¡é‡(mean, std)ï¼Œå¦‚æœNoneåˆ™è®¡ç®—
        
        Returns:
            normalized_features: å½’ä¸€åŒ–åçš„ç‰¹å¾å‘é‡
            stats: å½’ä¸€åŒ–ç»Ÿè®¡é‡
        """
        feature_vector = np.array([features[name] for name in self.feature_names], 
                                 dtype=np.float32)
        
        if stats is None:
            # ä½¿ç”¨ç®€å•çš„å½’ä¸€åŒ–ï¼ˆå‡è®¾æ¯ä¸ªç‰¹å¾çš„åˆç†èŒƒå›´ï¼‰
            feature_ranges = {
                'dof': (3, 7),
                'total_mass': (5, 50),
                'avg_link_mass': (0.5, 10),
                'max_link_mass': (1, 20),
                'total_inertia': (0.1, 10),
                'max_reach': (0.5, 2.0),
                'avg_link_length': (0.1, 0.5),
                'max_link_length': (0.2, 1.0),
                'payload_mass': (0, 5),
                'payload_distance': (0.5, 2.0)
            }
            
            means = np.array([(feature_ranges[name][0] + feature_ranges[name][1]) / 2 
                            for name in self.feature_names], dtype=np.float32)
            stds = np.array([(feature_ranges[name][1] - feature_ranges[name][0]) / 4 
                           for name in self.feature_names], dtype=np.float32)
            
            stats = {'mean': means, 'std': stds}
        
        normalized = (feature_vector - stats['mean']) / (stats['std'] + 1e-8)
        
        return normalized, stats


class MetaPIDNetwork(nn.Module):
    """å…ƒå­¦ä¹ PIDå‚æ•°é¢„æµ‹ç½‘ç»œ"""
    
    def __init__(self, feature_dim=10, max_dof=7, hidden_dims=[256, 256, 128]):
        """
        Args:
            feature_dim: è¾“å…¥ç‰¹å¾ç»´åº¦
            max_dof: æœ€å¤§è‡ªç”±åº¦
            hidden_dims: éšè—å±‚ç»´åº¦åˆ—è¡¨
        """
        super().__init__()
        
        self.feature_dim = feature_dim
        self.max_dof = max_dof
        
        # ç‰¹å¾ç¼–ç å™¨
        layers = []
        in_dim = feature_dim
        for h_dim in hidden_dims:
            layers.extend([
                nn.Linear(in_dim, h_dim),
                nn.LayerNorm(h_dim),
                nn.ReLU(),
                nn.Dropout(0.1)
            ])
            in_dim = h_dim
        
        self.encoder = nn.Sequential(*layers)
        
        # æ¯ä¸ªå…³èŠ‚çš„PIDå‚æ•°é¢„æµ‹å¤´
        self.kp_head = nn.Linear(hidden_dims[-1], max_dof)
        self.ki_head = nn.Linear(hidden_dims[-1], max_dof)
        self.kd_head = nn.Linear(hidden_dims[-1], max_dof)
        
        # å‚æ•°èŒƒå›´ï¼ˆç¡®ä¿ç‰©ç†åˆç†æ€§ï¼‰
        self.kp_min, self.kp_max = 10.0, 1000.0
        self.ki_min, self.ki_max = 0.1, 10.0
        self.kd_min, self.kd_max = 1.0, 50.0
    
    def forward(self, features, actual_dof=None):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            features: (batch, feature_dim) æœºå™¨äººç‰¹å¾
            actual_dof: å®é™…è‡ªç”±åº¦ï¼ˆç”¨äºè£å‰ªè¾“å‡ºï¼‰
        
        Returns:
            kp, ki, kd: (batch, dof) PIDå‚æ•°
        """
        # ç¼–ç ç‰¹å¾
        h = self.encoder(features)
        
        # é¢„æµ‹PIDå‚æ•°
        kp_raw = self.kp_head(h)
        ki_raw = self.ki_head(h)
        kd_raw = self.kd_head(h)
        
        # ç”¨Sigmoidå°†è¾“å‡ºé™åˆ¶åœ¨[0,1]ï¼Œç„¶åæ˜ å°„åˆ°åˆç†èŒƒå›´
        kp = self.kp_min + (self.kp_max - self.kp_min) * torch.sigmoid(kp_raw)
        ki = self.ki_min + (self.ki_max - self.ki_min) * torch.sigmoid(ki_raw)
        kd = self.kd_min + (self.kd_max - self.kd_min) * torch.sigmoid(kd_raw)
        
        # å¦‚æœæŒ‡å®šäº†å®é™…DOFï¼Œåªè¿”å›å‰actual_dofä¸ªå€¼
        if actual_dof is not None:
            kp = kp[:, :actual_dof]
            ki = ki[:, :actual_dof]
            kd = kd[:, :actual_dof]
        
        return kp, ki, kd
    
    def predict(self, features, actual_dof=None):
        """
        é¢„æµ‹æ¨¡å¼ï¼ˆæ— æ¢¯åº¦ï¼‰
        
        Args:
            features: (feature_dim,) æˆ– (batch, feature_dim)
            actual_dof: å®é™…è‡ªç”±åº¦
        
        Returns:
            kp, ki, kd: numpyæ•°ç»„
        """
        self.eval()
        with torch.no_grad():
            # ç¡®ä¿æ˜¯2D tensor
            if len(features.shape) == 1:
                features = features.unsqueeze(0)
            
            kp, ki, kd = self.forward(features, actual_dof)
            
            # è½¬ä¸ºnumpyå¹¶å»é™¤batchç»´åº¦ï¼ˆå¦‚æœè¾“å…¥æ˜¯1Dï¼‰
            kp = kp.cpu().numpy().squeeze()
            ki = ki.cpu().numpy().squeeze()
            kd = kd.cpu().numpy().squeeze()
            
            return kp, ki, kd


class MetaPIDOptimizer:
    """å…ƒå­¦ä¹ PIDä¼˜åŒ–å™¨ï¼ˆä¸»ç±»ï¼‰"""
    
    def __init__(self, model_path=None, device='cuda' if torch.cuda.is_available() else 'cpu'):
        """
        Args:
            model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device
        self.feature_extractor = RobotFeatureExtractor()
        
        # åˆ›å»ºæ¨¡å‹
        self.model = MetaPIDNetwork(
            feature_dim=len(self.feature_extractor.feature_names),
            max_dof=7,
            hidden_dims=[256, 256, 128]
        ).to(device)
        
        # å½’ä¸€åŒ–ç»Ÿè®¡é‡
        self.normalization_stats = None
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        if model_path is not None:
            self.load(model_path)
    
    def predict_pid(self, urdf_path, payload=0.0):
        """
        ä¸ºç»™å®šæœºå™¨äººé¢„æµ‹æœ€ä¼˜PIDå‚æ•°
        
        Args:
            urdf_path: æœºå™¨äººURDFè·¯å¾„
            payload: æœ«ç«¯è´Ÿè½½(kg)
        
        Returns:
            pid_params: dict with keys 'Kp', 'Ki', 'Kd' (numpy arrays)
            robot_info: dict with robot features and joint info
        """
        # æå–ç‰¹å¾
        features, controllable_joints = self.feature_extractor.extract_features(
            urdf_path, payload
        )
        
        # å½’ä¸€åŒ–
        normalized_features, _ = self.feature_extractor.normalize_features(
            features, self.normalization_stats
        )
        
        # è½¬ä¸ºtensor
        features_tensor = torch.FloatTensor(normalized_features).to(self.device)
        
        # é¢„æµ‹
        actual_dof = features['dof']
        kp, ki, kd = self.model.predict(features_tensor, actual_dof)
        
        pid_params = {
            'Kp': kp,
            'Ki': ki,
            'Kd': kd
        }
        
        robot_info = {
            'features': features,
            'controllable_joints': controllable_joints,
            'dof': actual_dof
        }
        
        return pid_params, robot_info
    
    def save(self, path):
        """ä¿å­˜æ¨¡å‹å’Œå½’ä¸€åŒ–ç»Ÿè®¡é‡"""
        save_dict = {
            'model_state_dict': self.model.state_dict(),
            'normalization_stats': self.normalization_stats,
            'feature_names': self.feature_extractor.feature_names
        }
        torch.save(save_dict, path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {path}")
    
    def load(self, path):
        """åŠ è½½æ¨¡å‹å’Œå½’ä¸€åŒ–ç»Ÿè®¡é‡"""
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.normalization_stats = checkpoint.get('normalization_stats')
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {path}")
    
    def to_yaml_config(self, pid_params, output_path):
        """
        å°†é¢„æµ‹çš„PIDå‚æ•°ä¿å­˜ä¸ºYAMLé…ç½®æ–‡ä»¶
        
        Args:
            pid_params: dict with 'Kp', 'Ki', 'Kd'
            output_path: è¾“å‡ºYAMLè·¯å¾„
        """
        config = {
            'pid_params': {
                'Kp': pid_params['Kp'].tolist(),
                'Ki': pid_params['Ki'].tolist(),
                'Kd': pid_params['Kd'].tolist()
            }
        }
        
        with open(output_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
        
        print(f"âœ… PIDé…ç½®å·²ä¿å­˜: {output_path}")


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    print("=" * 80)
    print("æµ‹è¯•å…ƒå­¦ä¹ PIDä¼˜åŒ–å™¨")
    print("=" * 80)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = MetaPIDOptimizer()
    
    # ä½¿ç”¨PyBulletè‡ªå¸¦çš„æœºå™¨äººURDFè¿›è¡Œæµ‹è¯•
    import pybullet_data
    
    # æµ‹è¯•å¤šä¸ªæœºå™¨äºº
    test_robots = [
        {
            'name': 'Kuka IIWA (7DOF)',
            'urdf': 'kuka_iiwa/model.urdf',
            'payloads': [0.0, 1.0, 2.0]
        },
        {
            'name': 'UR5 (6DOF)', 
            'urdf': 'urdf/ur5.urdf',
            'payloads': [0.0, 1.5]
        },
        {
            'name': 'Panda Arm (7DOF)',
            'urdf': 'franka_panda/panda.urdf',
            'payloads': [0.0, 0.5, 1.0]
        }
    ]
    
    print(f"\nå°†æµ‹è¯• {len(test_robots)} ç§æœºå™¨äºº...")
    print("ï¼ˆä½¿ç”¨PyBulletè‡ªå¸¦URDFï¼‰\n")
    
    success_count = 0
    
    for robot in test_robots:
        print("=" * 80)
        print(f"æµ‹è¯•: {robot['name']}")
        print("=" * 80)
        
        # å°è¯•åŠ è½½URDF
        urdf_path = robot['urdf']
        
        try:
            # æµ‹è¯•å¤šä¸ªè´Ÿè½½
            for payload in robot['payloads']:
                print(f"\nğŸ“¦ è´Ÿè½½: {payload} kg")
                print(f"ğŸ“Š æå–ç‰¹å¾...")
                
                features, joints = optimizer.feature_extractor.extract_features(
                    urdf_path, payload=payload
                )
                
                print(f"\nç‰¹å¾:")
                print(f"  DOF: {features['dof']}")
                print(f"  æ€»è´¨é‡: {features['total_mass']:.2f} kg")
                print(f"  æœ€å¤§åˆ°è¾¾è·ç¦»: {features['max_reach']:.2f} m")
                print(f"  è´Ÿè½½: {features['payload_mass']:.2f} kg")
                
                # æµ‹è¯•é¢„æµ‹ï¼ˆéšæœºåˆå§‹åŒ–çš„æ¨¡å‹ï¼‰
                print(f"\nğŸ”® é¢„æµ‹PIDå‚æ•°ï¼ˆæœªè®­ç»ƒæ¨¡å‹ï¼‰...")
                pid_params, robot_info = optimizer.predict_pid(urdf_path, payload=payload)
                
                print(f"\né¢„æµ‹çš„PIDå‚æ•°:")
                print(f"  Kp: {pid_params['Kp']}")
                print(f"  Ki: {pid_params['Ki']}")
                print(f"  Kd: {pid_params['Kd']}")
            
            success_count += 1
            print(f"\nâœ… {robot['name']} æµ‹è¯•æˆåŠŸï¼")
            
        except Exception as e:
            print(f"\nâš ï¸ {robot['name']} æµ‹è¯•å¤±è´¥: {e}")
            print(f"   ï¼ˆURDFå¯èƒ½åœ¨PyBulletæ•°æ®ä¸­ä¸å­˜åœ¨ï¼‰")
            continue
    
    print("\n" + "=" * 80)
    print(f"æµ‹è¯•å®Œæˆï¼æˆåŠŸ: {success_count}/{len(test_robots)}")
    print("=" * 80)
    
    if success_count > 0:
        print("\nâœ… å…ƒå­¦ä¹ PIDä¼˜åŒ–å™¨å·¥ä½œæ­£å¸¸ï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. æ”¶é›†è®­ç»ƒæ•°æ®: python meta_learning/collect_training_data.py")
        print("  2. è®­ç»ƒæ¨¡å‹: python meta_learning/train_meta_pid.py")
    else:
        print("\nâš ï¸ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥äº†")
        print("   è¿™å¯èƒ½æ˜¯å› ä¸ºPyBulletçš„æ•°æ®è·¯å¾„é—®é¢˜")
        print("   å»ºè®®ï¼šå‡†å¤‡è‡ªå·±çš„æœºå™¨äººURDFæ–‡ä»¶è¿›è¡Œæµ‹è¯•")

