#!/usr/bin/env python3
"""
ä»çœŸå®æ•°æ®è®¡ç®—Feature-PIDç›¸å…³æ€§
Author: AI Assistant
Date: 2025-01-30
"""

import numpy as np
import pandas as pd
import json
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# è®¾ç½®æœŸåˆŠé£æ ¼
plt.rcParams.update({
    'font.family': 'serif',
    'font.serif': ['Times New Roman', 'DejaVu Serif'],
    'font.size': 10,
    'axes.labelsize': 11,
    'axes.titlesize': 12,
    'xtick.labelsize': 9,
    'ytick.labelsize': 9,
    'legend.fontsize': 9,
    'figure.dpi': 300,
    'savefig.dpi': 300,
})

colors = {
    'primary': '#0173B2',
    'secondary': '#DE8F05',
    'success': '#029E73',
    'danger': '#D55E00',
    'purple': '#CC78BC',
    'neutral': '#949494',
}

def load_data(filepath='augmented_pid_data_filtered.json'):
    """åŠ è½½è¿‡æ»¤åçš„æ•°æ®"""
    print(f"ğŸ“‚ åŠ è½½æ•°æ®: {filepath}")
    with open(filepath, 'r') as f:
        data = json.load(f)
    print(f"âœ… æˆåŠŸåŠ è½½ {len(data)} ä¸ªæ ·æœ¬")
    return data

def extract_features_and_pid(data):
    """æå–ç‰¹å¾å’ŒPIDå‚æ•°"""
    features_list = []
    pid_list = []
    
    for sample in data:
        features = sample['features']
        pid = sample['optimal_pid']
        
        # æå–ç‰¹å¾
        feature_vec = [
            features['dof'],
            features['total_mass'],
            features['avg_link_mass'],
            features['total_inertia'],
            features['max_reach'],
            features.get('payload_mass', 0.0),
        ]
        
        # æå–PID
        pid_vec = [
            pid['kp'],
            pid['kd'],
            pid.get('ki', 0.0),  # æœ‰äº›å¯èƒ½æ²¡æœ‰ki
        ]
        
        features_list.append(feature_vec)
        pid_list.append(pid_vec)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    features_array = np.array(features_list)
    pid_array = np.array(pid_list)
    
    return features_array, pid_array

def calculate_correlation_with_pvalue(features_array, pid_array):
    """
    è®¡ç®—ç›¸å…³æ€§çŸ©é˜µå’Œpå€¼
    
    è¿”å›:
        correlation_matrix: ç›¸å…³ç³»æ•°çŸ©é˜µ
        pvalue_matrix: på€¼çŸ©é˜µ
    """
    n_features = features_array.shape[1]
    n_pids = pid_array.shape[1]
    
    correlation_matrix = np.zeros((n_features, n_pids))
    pvalue_matrix = np.zeros((n_features, n_pids))
    
    for i in range(n_features):
        for j in range(n_pids):
            # è®¡ç®—Pearsonç›¸å…³ç³»æ•°å’Œpå€¼
            corr, pval = pearsonr(features_array[:, i], pid_array[:, j])
            correlation_matrix[i, j] = corr
            pvalue_matrix[i, j] = pval
    
    return correlation_matrix, pvalue_matrix

def plot_correlation_heatmap(correlation_matrix, pvalue_matrix, save_path='feature_correlation_real.png'):
    """ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾"""
    
    features = ['DOF', 'Total Mass', 'Avg Link Mass', 'Total Inertia', 'Max Reach', 'Payload Mass']
    pid_params = ['Kp', 'Kd', 'Ki']
    
    fig, ax = plt.subplots(figsize=(7, 6))
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾
    im = ax.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')
    
    # è®¾ç½®åˆ»åº¦
    ax.set_xticks(np.arange(len(pid_params)))
    ax.set_yticks(np.arange(len(features)))
    ax.set_xticklabels(pid_params, fontsize=11, fontweight='bold')
    ax.set_yticklabels(features, fontsize=10)
    
    # åœ¨æ¯ä¸ªæ ¼å­ä¸­æ˜¾ç¤ºæ•°å€¼å’Œæ˜¾è‘—æ€§
    for i in range(len(features)):
        for j in range(len(pid_params)):
            corr = correlation_matrix[i, j]
            pval = pvalue_matrix[i, j]
            
            # æ ¹æ®på€¼æ·»åŠ æ˜¾è‘—æ€§æ ‡è®°
            if pval < 0.001:
                significance = '***'
            elif pval < 0.01:
                significance = '**'
            elif pval < 0.05:
                significance = '*'
            else:
                significance = ''
            
            text_color = 'white' if abs(corr) > 0.5 else 'black'
            ax.text(j, i, f'{corr:.2f}\n{significance}',
                   ha="center", va="center", color=text_color,
                   fontsize=9, fontweight='bold')
    
    # æ·»åŠ é¢œè‰²æ¡
    cbar = plt.colorbar(im, ax=ax, pad=0.03, shrink=0.95)
    cbar.set_label('Pearson Correlation Coefficient', rotation=270, labelpad=20, fontsize=10)
    
    # è®¾ç½®æ ‡é¢˜
    n_samples = correlation_matrix.shape[0] * correlation_matrix.shape[1]
    ax.set_title('Correlation Between Robot Features and Optimal PID Parameters\n' + 
                '(232 Filtered Samples, *** p<0.001, ** p<0.01, * p<0.05)',
                fontsize=11, fontweight='bold', pad=15)
    
    ax.set_xlabel('PID Parameters', fontsize=11, fontweight='bold')
    ax.set_ylabel('Robot Features', fontsize=11, fontweight='bold')
    
    # æ·»åŠ ç½‘æ ¼
    ax.set_xticks(np.arange(len(pid_params)+1)-.5, minor=True)
    ax.set_yticks(np.arange(len(features)+1)-.5, minor=True)
    ax.grid(which="minor", color="gray", linestyle='-', linewidth=1.5)
    ax.tick_params(which="minor", size=0)
    
    # ä¿å­˜
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.savefig(save_path.replace('.png', '.pdf'), bbox_inches='tight')
    print(f"\nâœ… å·²ä¿å­˜: {save_path}")
    plt.close()

def print_correlation_analysis(correlation_matrix, pvalue_matrix):
    """æ‰“å°è¯¦ç»†çš„ç›¸å…³æ€§åˆ†æ"""
    features = ['DOF', 'Total Mass', 'Avg Link Mass', 'Total Inertia', 'Max Reach', 'Payload Mass']
    pid_params = ['Kp', 'Kd', 'Ki']
    
    print("\n" + "="*80)
    print("ğŸ“Š Feature-PID ç›¸å…³æ€§åˆ†æï¼ˆåŸºäºçœŸå®æ•°æ®ï¼‰")
    print("="*80)
    
    for j, pid in enumerate(pid_params):
        print(f"\nğŸ¯ {pid} çš„ç›¸å…³æ€§æ’å:")
        print("-" * 60)
        
        # åˆ›å»ºç›¸å…³æ€§åˆ—è¡¨
        corr_list = [(features[i], correlation_matrix[i, j], pvalue_matrix[i, j]) 
                     for i in range(len(features))]
        
        # æŒ‰ç›¸å…³æ€§ç»å¯¹å€¼æ’åº
        corr_list.sort(key=lambda x: abs(x[1]), reverse=True)
        
        for feat, corr, pval in corr_list:
            # æ˜¾è‘—æ€§æ ‡è®°
            if pval < 0.001:
                sig = '***'
            elif pval < 0.01:
                sig = '**'
            elif pval < 0.05:
                sig = '*'
            else:
                sig = 'ns'
            
            # ç›¸å…³æ€§å¼ºåº¦æè¿°
            if abs(corr) > 0.7:
                strength = "æå¼º"
            elif abs(corr) > 0.5:
                strength = "å¼º"
            elif abs(corr) > 0.3:
                strength = "ä¸­ç­‰"
            elif abs(corr) > 0.1:
                strength = "å¼±"
            else:
                strength = "æå¼±"
            
            print(f"  {feat:20s}: {corr:+6.3f} {sig:3s}  (p={pval:.4f}) - {strength}ç›¸å…³")
    
    print("\n" + "="*80)
    
    # ç»Ÿè®¡æ˜¾è‘—ç›¸å…³çš„æ•°é‡
    n_total = correlation_matrix.size
    n_sig_001 = np.sum(pvalue_matrix < 0.001)
    n_sig_01 = np.sum((pvalue_matrix >= 0.001) & (pvalue_matrix < 0.01))
    n_sig_05 = np.sum((pvalue_matrix >= 0.01) & (pvalue_matrix < 0.05))
    n_nonsig = np.sum(pvalue_matrix >= 0.05)
    
    print(f"ğŸ“ˆ æ˜¾è‘—æ€§ç»Ÿè®¡:")
    print(f"  p < 0.001 (***): {n_sig_001}/{n_total} ({n_sig_001/n_total*100:.1f}%)")
    print(f"  p < 0.01  (** ): {n_sig_01}/{n_total} ({n_sig_01/n_total*100:.1f}%)")
    print(f"  p < 0.05  (*  ): {n_sig_05}/{n_total} ({n_sig_05/n_total*100:.1f}%)")
    print(f"  p â‰¥ 0.05  (ns ): {n_nonsig}/{n_total} ({n_nonsig/n_total*100:.1f}%)")
    print("="*80 + "\n")

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print("ğŸ”¬ ä»çœŸå®æ•°æ®è®¡ç®—Feature-PIDç›¸å…³æ€§")
    print("="*80 + "\n")
    
    # 1. åŠ è½½æ•°æ®
    data = load_data('augmented_pid_data_filtered.json')
    
    # 2. æå–ç‰¹å¾å’ŒPID
    features_array, pid_array = extract_features_and_pid(data)
    print(f"\nğŸ“Š æ•°æ®ç»´åº¦:")
    print(f"  ç‰¹å¾çŸ©é˜µ: {features_array.shape} (æ ·æœ¬æ•° Ã— ç‰¹å¾æ•°)")
    print(f"  PIDçŸ©é˜µ: {pid_array.shape} (æ ·æœ¬æ•° Ã— PIDå‚æ•°æ•°)")
    
    # 3. è®¡ç®—ç›¸å…³æ€§
    print(f"\nğŸ” è®¡ç®—Pearsonç›¸å…³ç³»æ•°å’Œpå€¼...")
    correlation_matrix, pvalue_matrix = calculate_correlation_with_pvalue(features_array, pid_array)
    
    # 4. æ‰“å°åˆ†æ
    print_correlation_analysis(correlation_matrix, pvalue_matrix)
    
    # 5. ç»˜åˆ¶çƒ­åŠ›å›¾
    print("ğŸ¨ ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾...")
    plot_correlation_heatmap(correlation_matrix, pvalue_matrix)
    
    # 6. ä¿å­˜æ•°æ®ä¸ºCSVä¾›æŸ¥çœ‹
    features = ['DOF', 'Total Mass', 'Avg Link Mass', 'Total Inertia', 'Max Reach', 'Payload Mass']
    pid_params = ['Kp', 'Kd', 'Ki']
    
    df_corr = pd.DataFrame(correlation_matrix, index=features, columns=pid_params)
    df_pval = pd.DataFrame(pvalue_matrix, index=features, columns=pid_params)
    
    df_corr.to_csv('correlation_coefficients.csv')
    df_pval.to_csv('correlation_pvalues.csv')
    
    print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜:")
    print(f"  - correlation_coefficients.csv")
    print(f"  - correlation_pvalues.csv")
    
    print("\nâœ… åˆ†æå®Œæˆï¼")
    print("="*80 + "\n")

if __name__ == '__main__':
    main()

