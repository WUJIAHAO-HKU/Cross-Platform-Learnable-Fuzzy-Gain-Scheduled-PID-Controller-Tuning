#!/usr/bin/env python3
"""
è¿‡æ»¤æ‰Laikagoè™šæ‹Ÿæ ·æœ¬ï¼Œåªä¿ç•™é«˜è´¨é‡æ ·æœ¬
"""

import json
from pathlib import Path

# åŠ è½½ä¼˜åŒ–åçš„æ•°æ®
data_path = Path(__file__).parent / 'augmented_pid_data_optimized.json'
with open(data_path, 'r') as f:
    data = json.load(f)

print("=" * 80)
print("è¿‡æ»¤Laikagoè™šæ‹Ÿæ ·æœ¬")
print("=" * 80)

print(f"\nåŸå§‹æ•°æ®: {len(data)}ä¸ªæ ·æœ¬")

# ç»Ÿè®¡
types_count = {}
for d in data:
    name = d['name']
    if d['type'] == 'real':
        key = f"çœŸå®-{name}"
    elif 'laikago' in name:
        key = "è™šæ‹Ÿ-Laikago"
    elif 'panda' in name:
        key = "è™šæ‹Ÿ-Panda"
    else:
        key = "è™šæ‹Ÿ-KUKA"
    types_count[key] = types_count.get(key, 0) + 1

print("\næ ·æœ¬åˆ†å¸ƒ:")
for key, count in sorted(types_count.items()):
    print(f"   {key}: {count}")

# è¿‡æ»¤ï¼šä¿ç•™æ‰€æœ‰çœŸå®æ ·æœ¬ + Pandaè™šæ‹Ÿæ ·æœ¬ + KUKAè™šæ‹Ÿæ ·æœ¬
filtered_data = [
    d for d in data 
    if d['type'] == 'real' or 'laikago' not in d['name'].lower()
]

print(f"\nè¿‡æ»¤å: {len(filtered_data)}ä¸ªæ ·æœ¬")
print(f"   æ’é™¤: {len(data) - len(filtered_data)}ä¸ªLaikagoè™šæ‹Ÿæ ·æœ¬")

# ç»Ÿè®¡è¿‡æ»¤åçš„ä¼˜åŒ–è¯¯å·®
errors = [d.get('optimization_error_deg', 0) for d in filtered_data]
import numpy as np

print(f"\nè¿‡æ»¤åä¼˜åŒ–è¯¯å·®ç»Ÿè®¡:")
print(f"   å¹³å‡: {np.mean(errors):.2f}Â°")
print(f"   ä¸­ä½: {np.median(errors):.2f}Â°")
print(f"   æœ€å°: {np.min(errors):.2f}Â°")
print(f"   æœ€å¤§: {np.max(errors):.2f}Â°")
print(f"   <10Â°: {sum(1 for e in errors if e < 10)} æ ·æœ¬")
print(f"   10-30Â°: {sum(1 for e in errors if 10 <= e < 30)} æ ·æœ¬")
print(f"   â‰¥30Â°: {sum(1 for e in errors if e >= 30)} æ ·æœ¬")

# ä¿å­˜è¿‡æ»¤åçš„æ•°æ®
output_path = Path(__file__).parent / 'augmented_pid_data_filtered.json'
with open(output_path, 'w') as f:
    json.dump(filtered_data, f, indent=2)

print(f"\nğŸ’¾ è¿‡æ»¤åæ•°æ®å·²ä¿å­˜: {output_path}")

print("\n" + "=" * 80)
print("âœ… è¿‡æ»¤å®Œæˆï¼")
print("=" * 80)
print(f"\nğŸ¯ ä¸‹ä¸€æ­¥:")
print(f"   python train_with_filtered_data.py")

