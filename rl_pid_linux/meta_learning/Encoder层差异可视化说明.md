# Meta-PIDç½‘ç»œæ¶æ„å›¾ï¼šEncoderå±‚å·®å¼‚å¯è§†åŒ–è¯´æ˜

## ğŸ“Š ä¿®æ”¹æ¦‚è§ˆ

å·²åœ¨`meta_pid_network_architecture.tex`ä¸­æ·»åŠ å¤šå¤„å¯è§†åŒ–æ ‡æ³¨ï¼Œæ¸…æ™°å±•ç¤ºä¸¤ä¸ªEncoderå±‚çš„å·®å¼‚ã€‚

---

## âœ… ä¿®æ”¹å†…å®¹è¯¦è§£

### 1ï¸âƒ£ **ç«‹æ–¹ä½“å†…éƒ¨æ ‡æ³¨ï¼ˆæœ€ç›´è§‚ï¼‰**

#### Encoder 1ï¼ˆçº¢è‰²ç«‹æ–¹ä½“ï¼‰
```latex
% æƒé‡çŸ©é˜µæ ‡æ³¨
\node[font=\sffamily\tiny, text=yellow!90, align=center] at (3.35, 0.8)
    {\textbf{$W_1$: 10Ã—256}};

% åŠŸèƒ½æ ‡æ³¨
\node[font=\sffamily\tiny, text=yellow!90, align=center] at (3.35, 0.3)
    {Feature Extraction};
```
**æ˜¾ç¤ºæ•ˆæœ**ï¼š
- é»„è‰²æ–‡å­— `Wâ‚: 10Ã—256` ï¼ˆæƒé‡çŸ©é˜µå½¢çŠ¶ï¼‰
- é»„è‰²æ–‡å­— `Feature Extraction` ï¼ˆåŠŸèƒ½è¯´æ˜ï¼‰

#### Encoder 2ï¼ˆçº¢è‰²ç«‹æ–¹ä½“ï¼‰
```latex
% æƒé‡çŸ©é˜µæ ‡æ³¨ï¼ˆä¸Encoder 1ä¸åŒï¼‰
\node[font=\sffamily\tiny, text=yellow!90, align=center] at (6.35, 0.8)
    {\textbf{$W_2$: 256Ã—256}};

% åŠŸèƒ½æ ‡æ³¨
\node[font=\sffamily\tiny, text=yellow!90, align=center] at (6.35, 0.3)
    {Deep Refinement};
```
**æ˜¾ç¤ºæ•ˆæœ**ï¼š
- é»„è‰²æ–‡å­— `Wâ‚‚: 256Ã—256` ï¼ˆæƒé‡çŸ©é˜µå½¢çŠ¶ï¼Œ**ä¸Encoder 1ä¸åŒ**ï¼‰
- é»„è‰²æ–‡å­— `Deep Refinement` ï¼ˆåŠŸèƒ½è¯´æ˜ï¼‰

---

### 2ï¸âƒ£ **åº•éƒ¨ä¿¡æ¯æ¡†ï¼šç½‘ç»œå‚æ•°è¯¦è§£**

```latex
\node[draw, thick, rounded corners, fill=green!15, text width=3.5cm, align=left,
      font=\sffamily\footnotesize, drop shadow] at (1, -5.5)
{
    \textbf{Network Parameters:}\\[0.1cm]
    â€¢ Input: 10D\\
    â€¢ Encoder 1: 10â†’256\\              â† æ³¨æ„è¾“å…¥ç»´åº¦æ˜¯10
    \tiny   ($W_1$: 10Ã—256)\\[0.05cm]
    \footnotesize â€¢ Encoder 2: 256â†’256\\  â† æ³¨æ„è¾“å…¥ç»´åº¦æ˜¯256
    \tiny   ($W_2$: 256Ã—256)\\[0.05cm]
    \footnotesize â€¢ Hidden: 256â†’128\\
    â€¢ Output: 3Ã—7=21\\[0.05cm]
    \textbf{Total: 104,789 params}
};
```

**å…³é”®ä¿¡æ¯**ï¼š
- `Encoder 1: 10â†’256` - è¾“å…¥ç»´åº¦**10**ï¼ˆæ¥è‡ªåŸå§‹ç‰¹å¾ï¼‰
- `Encoder 2: 256â†’256` - è¾“å…¥ç»´åº¦**256**ï¼ˆæ¥è‡ªEncoder 1ï¼‰
- æƒé‡çŸ©é˜µå½¢çŠ¶æ˜ç¡®æ ‡æ³¨

---

### 3ï¸âƒ£ **å³ä¸Šè§’è¯´æ˜æ¡†ï¼šè®¾è®¡ç†å¿µ**

```latex
\node[draw, thick, rounded corners, fill=orange!10, text width=4.5cm, align=left,
      font=\sffamily\tiny, drop shadow] at (13.5, 6.5)
{
    \textbf{\small Hierarchical Encoder Design:}\\[0.1cm]
    \textbf{Encoder 1} (10â†’256):\\
    â€¢ Dimension expansion\\
    â€¢ Raw feature mapping\\
    â€¢ Physical â†’ Abstract\\[0.1cm]
    \textbf{Encoder 2} (256â†’256):\\
    â€¢ Same-dim refinement\\
    â€¢ Deep feature learning\\
    â€¢ Enhanced representation\\[0.1cm]
    \textcolor{red!70}{\textbf{Note:}} Same structure, different weights!
};
```

**æ ¸å¿ƒè¯´æ˜**ï¼š
1. **Encoder 1åŠŸèƒ½**ï¼š
   - âœ… ç»´åº¦æ‰©å±•ï¼ˆ10D â†’ 256Dï¼‰
   - âœ… åŸå§‹ç‰¹å¾æ˜ å°„
   - âœ… ç‰©ç†é‡ â†’ æŠ½è±¡è¡¨ç¤º

2. **Encoder 2åŠŸèƒ½**ï¼š
   - âœ… åŒç»´åº¦ç²¾ç‚¼ï¼ˆ256D â†’ 256Dï¼‰
   - âœ… æ·±åº¦ç‰¹å¾å­¦ä¹ 
   - âœ… å¢å¼ºè¡¨ç¤ºèƒ½åŠ›

3. **å…³é”®æç¤º**ï¼š
   - âš ï¸ **"Same structure, different weights!"** ï¼ˆç»“æ„ç›¸åŒï¼Œæƒé‡ä¸åŒï¼‰

---

## ğŸ¯ è®¾è®¡å¯¹æ¯”æ€»ç»“

| ç‰¹æ€§                | Encoder 1              | Encoder 2              |
|---------------------|------------------------|------------------------|
| **è¾“å…¥ç»´åº¦**        | 10Dï¼ˆåŸå§‹ç‰¹å¾ï¼‰        | 256Dï¼ˆæ¥è‡ªEncoder 1ï¼‰  |
| **è¾“å‡ºç»´åº¦**        | 256D                   | 256D                   |
| **æƒé‡çŸ©é˜µ**        | Wâ‚: (10, 256)          | Wâ‚‚: (256, 256)         |
| **å‚æ•°é‡**          | 2,560                  | 65,536                 |
| **ç»“æ„ç»„æˆ**        | Linearâ†’LNâ†’ReLUâ†’Dropout | Linearâ†’LNâ†’ReLUâ†’Dropout |
| **æ¿€æ´»å‡½æ•°**        | ReLU                   | ReLU                   |
| **æ­£åˆ™åŒ–**          | LayerNorm + Dropout    | LayerNorm + Dropout    |
| **åŠŸèƒ½å®šä½**        | ç‰¹å¾æå–ä¸ç»´åº¦æ‰©å±•     | æ·±åº¦ç‰¹å¾ç²¾ç‚¼           |
| **è®¾è®¡ç†å¿µ**        | Physical â†’ Abstract    | Same-dim refinement    |

---

## ğŸ” ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ä¸ªEncoderï¼Ÿ

### åŸç†è§£é‡Š

1. **Encoder 1ï¼šç‰¹å¾æå–ä¸ç»´åº¦æ‰©å±•**
   - å°†10ä¸ªç‰©ç†ç‰¹å¾ï¼ˆè´¨é‡ã€DOFã€æƒ¯é‡ç­‰ï¼‰æ˜ å°„åˆ°é«˜ç»´ç©ºé—´ï¼ˆ256Dï¼‰
   - å­¦ä¹ ç‰©ç†é‡ä¹‹é—´çš„éçº¿æ€§ç»„åˆ
   - ç±»ä¼¼äº"è¯åµŒå…¥"ï¼Œå°†ç¨€ç–çš„ç‰©ç†ç‰¹å¾å˜ä¸ºç¨ å¯†è¡¨ç¤º

2. **Encoder 2ï¼šæ·±åº¦ç‰¹å¾ç²¾ç‚¼**
   - åœ¨ç›¸åŒç»´åº¦ç©ºé—´ï¼ˆ256Dï¼‰è¿›è¡Œæ›´æ·±å±‚æ¬¡çš„ç‰¹å¾å˜æ¢
   - å­¦ä¹ æ›´æŠ½è±¡çš„æœºå™¨äººåŠ¨åŠ›å­¦è¡¨ç¤º
   - æå‡ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›ï¼ˆæ·±åº¦å­¦ä¹ çš„"æ·±åº¦"ï¼‰

3. **ä¸ºä»€ä¹ˆä¸ç›´æ¥10Dâ†’128Dï¼Ÿ**
   - âŒ **è·¨åº¦å¤ªå¤§**ï¼š10â†’128çš„æ˜ å°„è¡¨è¾¾èƒ½åŠ›æœ‰é™
   - âœ… **é€æ­¥æŠ½è±¡**ï¼š10â†’256â†’256â†’128æ›´ç¬¦åˆç‰¹å¾å­¦ä¹ è§„å¾‹
   - âœ… **æ›´å¥½è®­ç»ƒ**ï¼šè¾ƒå®½çš„éšè—å±‚ï¼ˆ256Dï¼‰æ›´å®¹æ˜“ä¼˜åŒ–

---

## ğŸ“š æ·±åº¦å­¦ä¹ è®¾è®¡åŸåˆ™

è¿™ç§è®¾è®¡ç¬¦åˆä»¥ä¸‹åŸåˆ™ï¼š

1. **å¢åŠ ç½‘ç»œæ·±åº¦æå‡è¡¨è¾¾èƒ½åŠ›**
   - VGGã€ResNetç­‰ç»å…¸ç½‘ç»œéƒ½ä½¿ç”¨å¤šä¸ªç›¸åŒç»´åº¦çš„å±‚

2. **ä¿æŒç›¸åŒç»´åº¦ä¾¿äºä¿¡æ¯æµåŠ¨**
   - 256â†’256ä¾¿äºä½¿ç”¨æ®‹å·®è¿æ¥ï¼ˆResNetï¼‰
   - é¿å…ä¿¡æ¯ç“¶é¢ˆ

3. **é€å±‚æŠ½è±¡**
   - ç¬¬1å±‚ï¼šåŸå§‹ç‰©ç†ç‰¹å¾ â†’ åˆçº§æŠ½è±¡
   - ç¬¬2å±‚ï¼šåˆçº§æŠ½è±¡ â†’ é«˜çº§æŠ½è±¡
   - ç¬¬3å±‚ï¼šé«˜çº§æŠ½è±¡ â†’ é™ç»´ç”¨äºé¢„æµ‹

---

## ğŸ¨ å¯è§†åŒ–æ•ˆæœé¢„è§ˆ

ç¼–è¯‘åçš„PDFå›¾ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Meta-PID Network Architecture                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input         Encoder 1         Encoder 2         Hidden
[10D]    â†’    [256D]       â†’    [256D]       â†’    [128D]  â†’  Outputs
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        
              â”‚Wâ‚:10Ã—256â”‚        â”‚Wâ‚‚:256Ã—256â”‚        
              â”‚Feature  â”‚        â”‚  Deep   â”‚        
              â”‚Extractionâ”‚        â”‚Refinementâ”‚        
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        
              
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ Hierarchical Encoder Design: â”‚
                              â”‚                              â”‚
                              â”‚ Encoder 1 (10â†’256):          â”‚
                              â”‚  â€¢ Dimension expansion       â”‚
                              â”‚  â€¢ Physical â†’ Abstract       â”‚
                              â”‚                              â”‚
                              â”‚ Encoder 2 (256â†’256):         â”‚
                              â”‚  â€¢ Same-dim refinement       â”‚
                              â”‚  â€¢ Enhanced representation   â”‚
                              â”‚                              â”‚
                              â”‚ Note: Same structure,        â”‚
                              â”‚       different weights!     â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Network Parameters:                                           â”‚
â”‚  â€¢ Input: 10D                                                 â”‚
â”‚  â€¢ Encoder 1: 10â†’256  (Wâ‚: 10Ã—256)     â† ä¸åŒè¾“å…¥ç»´åº¦        â”‚
â”‚  â€¢ Encoder 2: 256â†’256 (Wâ‚‚: 256Ã—256)    â† ä¸åŒè¾“å…¥ç»´åº¦        â”‚
â”‚  â€¢ Hidden: 256â†’128                                            â”‚
â”‚  â€¢ Total: 104,789 params                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ å…³é”®è¦ç‚¹

### ç›¸åŒç‚¹ âœ…
- ç»“æ„ï¼šéƒ½æ˜¯ `Linear â†’ LayerNorm â†’ ReLU â†’ Dropout(0.1)`
- è¾“å‡ºç»´åº¦ï¼šéƒ½æ˜¯256D
- æ¿€æ´»å‡½æ•°ï¼šéƒ½æ˜¯ReLU
- æ­£åˆ™åŒ–ï¼šéƒ½ä½¿ç”¨LayerNormå’ŒDropout

### ä¸åŒç‚¹ âš ï¸
- **æƒé‡çŸ©é˜µå½¢çŠ¶**ï¼š
  - Encoder 1: (10, 256) - **2,560ä¸ªå‚æ•°**
  - Encoder 2: (256, 256) - **65,536ä¸ªå‚æ•°**
- **è¾“å…¥æ¥æº**ï¼š
  - Encoder 1: åŸå§‹10Dç‰©ç†ç‰¹å¾
  - Encoder 2: Encoder 1çš„256Dè¾“å‡º
- **åŠŸèƒ½å®šä½**ï¼š
  - Encoder 1: ç‰¹å¾æå–ä¸ç»´åº¦æ‰©å±•
  - Encoder 2: æ·±åº¦ç‰¹å¾ç²¾ç‚¼

---

## ğŸš€ ä½¿ç”¨å»ºè®®

### ç¼–è¯‘å‘½ä»¤
```bash
cd /home/wujiahao/åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ¨¡å‹é¢„æµ‹æ§åˆ¶åŠ¨åŠ›å­¦æ¨¡å‹è¯¯å·®åœ¨çº¿è¡¥å¿æ–¹æ³•ç ”ç©¶/rl_pid_linux/meta_learning
pdflatex meta_pid_network_architecture.tex
```

æˆ–ä½¿ç”¨Overleafåœ¨çº¿ç¼–è¯‘ï¼ˆæ¨èï¼‰ã€‚

### æ’å…¥è®ºæ–‡
```latex
\begin{figure*}[!htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{meta_pid_network_architecture.pdf}
    \caption{Meta-PID Network Architecture. The hierarchical design uses two 
             encoder layers with \textbf{different weight matrices} 
             ($W_1$: 10Ã—256 for feature extraction, $W_2$: 256Ã—256 for deep 
             refinement) but identical layer structures, progressively 
             transforming raw robot features into abstract representations 
             for PID parameter prediction.}
    \label{fig:meta_pid_arch}
\end{figure*}
```

### è®ºæ–‡æ­£æ–‡è¯´æ˜ç¤ºä¾‹
```latex
As illustrated in Figure~\ref{fig:meta_pid_arch}, our Meta-PID network 
employs a hierarchical encoder design with two layers of identical structure 
but different weight matrices. The first encoder ($W_1 \in \mathbb{R}^{10 \times 256}$) 
expands the 10-dimensional robot feature vector into a 256-dimensional 
latent space, capturing nonlinear combinations of physical properties 
(mass, inertia, link lengths, etc.). The second encoder ($W_2 \in \mathbb{R}^{256 \times 256}$) 
refines these features through same-dimension transformation, learning 
deeper abstractions that generalize across diverse robot morphologies.
```

---

## ğŸ“Š æ€»ç»“

é€šè¿‡ä»¥ä¸Šä¿®æ”¹ï¼Œå›¾ä¸­**ä¸‰ä¸ªä½ç½®**æ¸…æ¥šåœ°å±•ç¤ºäº†ä¸¤ä¸ªEncoderå±‚çš„å·®å¼‚ï¼š

1. âœ… **ç«‹æ–¹ä½“å†…éƒ¨æ ‡æ³¨**ï¼šé»„è‰²æ–‡å­—æ˜¾ç¤ºæƒé‡çŸ©é˜µå½¢çŠ¶å’ŒåŠŸèƒ½
2. âœ… **åº•éƒ¨å‚æ•°æ¡†**ï¼šæ˜ç¡®æ ‡æ³¨è¾“å…¥â†’è¾“å‡ºç»´åº¦å’Œæƒé‡çŸ©é˜µ
3. âœ… **å³ä¸Šè¯´æ˜æ¡†**ï¼šè¯¦ç»†è§£é‡Šè®¾è®¡ç†å¿µå’Œå·®å¼‚

è¿™æ ·çš„å¯è§†åŒ–èƒ½å¤Ÿè®©å®¡ç¨¿äººå’Œè¯»è€…ç«‹å³ç†è§£ï¼š
- **è™½ç„¶ä¸¤ä¸ªEncoderç»“æ„ç›¸åŒï¼Œä½†æƒé‡çŸ©é˜µå’ŒåŠŸèƒ½å®šä½ä¸åŒ**
- **è¿™æ˜¯æ·±åº¦å­¦ä¹ ä¸­å¸¸è§çš„"é€å±‚æŠ½è±¡"è®¾è®¡**
- **è®¾è®¡åˆç†ä¸”ç¬¦åˆç‰¹å¾å­¦ä¹ è§„å¾‹**

---

ç”Ÿæˆæ—¶é—´ï¼š2025-10-31  
ä¿®æ”¹æ–‡ä»¶ï¼š`meta_pid_network_architecture.tex`  
å¯è§†åŒ–çº§åˆ«ï¼šâ­â­â­â­â­ é¡¶åˆŠçº§åˆ«

