#!/usr/bin/env python3
"""
å¤šåœºæ™¯æ‰°åŠ¨è®­ç»ƒè„šæœ¬
é’ˆå¯¹4ç§æ‰°åŠ¨ç±»å‹è®­ç»ƒç‹¬ç«‹çš„RL agent
"""

import os
import sys
from pathlib import Path
from train_adaptive_rl import train_adaptive_rl

# æ‰°åŠ¨åœºæ™¯é…ç½®
DISTURBANCE_SCENARIOS = {
    'random_force': {
        'type': 'random_force',
        'force_range': (1.0, 3.0),
        'force_interval': 800,
        'force_duration': 100,
        'description': 'éšæœºå¤–åŠ›ï¼ˆ1ï½3Nä¾§æ¨ï¼‰'
    },
    'payload': {
        'type': 'payload',
        'payload_range': (0.0, 5.0),
        'payload_interval': 1000,
        'description': 'åŠ¨æ€è´Ÿè½½ï¼ˆ0ï½5kgï¼‰'
    },
    'terrain': {
        'type': 'terrain',
        'terrain_angle_range': (0, 15),
        'terrain_interval': 2000,
        'description': 'åœ°å½¢å˜åŒ–ï¼ˆ0ï½15Â°æ–œå¡ï¼‰'
    },
    'param_uncertainty': {
        'type': 'param_uncertainty',
        'param_uncertainty': 0.2,
        'description': 'å‚æ•°ä¸ç¡®å®šæ€§ï¼ˆÂ±20%è´¨é‡ï¼‰'
    },
    'mixed': {
        'type': 'mixed',
        'force_range': (1.0, 3.0),
        'force_interval': 800,
        'force_duration': 100,
        'payload_range': (0.0, 5.0),
        'payload_interval': 1000,
        'description': 'æ··åˆæ‰°åŠ¨ï¼ˆå¤–åŠ›+è´Ÿè½½ï¼‰'
    }
}


def train_all_scenarios(
    scenarios=['random_force', 'payload', 'terrain', 'param_uncertainty'],
    total_timesteps=500000,
    n_envs=4,
    use_gpu=True
):
    """
    è®­ç»ƒæ‰€æœ‰æ‰°åŠ¨åœºæ™¯
    
    Args:
        scenarios: è¦è®­ç»ƒçš„åœºæ™¯åˆ—è¡¨
        total_timesteps: æ¯ä¸ªåœºæ™¯çš„è®­ç»ƒæ­¥æ•°
        n_envs: å¹¶è¡Œç¯å¢ƒæ•°é‡
        use_gpu: æ˜¯å¦ä½¿ç”¨GPU
    """
    print("=" * 80)
    print("å¤šåœºæ™¯è‡ªé€‚åº”RLè®­ç»ƒ")
    print("=" * 80)
    print(f"\nğŸ“‹ è®¡åˆ’è®­ç»ƒåœºæ™¯: {len(scenarios)}ä¸ª")
    for scenario in scenarios:
        print(f"   - {scenario}: {DISTURBANCE_SCENARIOS[scenario]['description']}")
    
    print(f"\nâ±ï¸  é¢„è®¡æ€»æ—¶é—´: {len(scenarios) * 2.5:.1f}å°æ—¶ï¼ˆæ¯åœºæ™¯çº¦2.5å°æ—¶@GPUï¼‰")
    print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜ä½ç½®: ./logs/adaptive_rl/")
    
    input("\næŒ‰Enterå¼€å§‹è®­ç»ƒï¼Œæˆ–Ctrl+Cå–æ¶ˆ...")
    
    results = {}
    
    for i, scenario in enumerate(scenarios, 1):
        print("\n" + "=" * 80)
        print(f"è®­ç»ƒåœºæ™¯ {i}/{len(scenarios)}: {scenario}")
        print(f"æè¿°: {DISTURBANCE_SCENARIOS[scenario]['description']}")
        print("=" * 80)
        
        try:
            # ä½¿ç”¨åœºæ™¯ç‰¹å®šçš„é…ç½®è®­ç»ƒ
            model_path = train_adaptive_rl(
                total_timesteps=total_timesteps,
                n_envs=n_envs,
                disturbance_type=scenario,
                use_gpu=use_gpu
            )
            
            results[scenario] = {
                'status': 'success',
                'model_path': model_path
            }
            
            print(f"\nâœ… {scenario} è®­ç»ƒå®Œæˆï¼")
            print(f"   æ¨¡å‹: {model_path}")
            
        except KeyboardInterrupt:
            print(f"\nâš ï¸  {scenario} è®­ç»ƒè¢«ä¸­æ–­")
            results[scenario] = {'status': 'interrupted'}
            break
        except Exception as e:
            print(f"\nâŒ {scenario} è®­ç»ƒå¤±è´¥: {e}")
            results[scenario] = {'status': 'failed', 'error': str(e)}
            continue
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("è®­ç»ƒæ€»ç»“")
    print("=" * 80)
    
    for scenario, result in results.items():
        status_icon = {'success': 'âœ…', 'interrupted': 'âš ï¸', 'failed': 'âŒ'}.get(result['status'], 'â“')
        print(f"{status_icon} {scenario}: {result['status']}")
        if result['status'] == 'success':
            print(f"   æ¨¡å‹: {result.get('model_path', 'N/A')}")
    
    return results


def quick_test_all_scenarios(steps=5000, gui=False):
    """
    å¿«é€Ÿæµ‹è¯•æ‰€æœ‰æ‰°åŠ¨åœºæ™¯ï¼ˆéªŒè¯ç¯å¢ƒï¼‰
    
    Args:
        steps: æ¯ä¸ªåœºæ™¯æµ‹è¯•æ­¥æ•°
        gui: æ˜¯å¦æ˜¾ç¤ºGUI
    """
    import sys
    sys.path.append(str(Path(__file__).parent))
    from adaptive_laikago_env import LaikagoAdaptiveEnv
    
    print("=" * 80)
    print("å¿«é€Ÿæµ‹è¯•æ‰€æœ‰æ‰°åŠ¨åœºæ™¯")
    print("=" * 80)
    
    for scenario_name, scenario_config in DISTURBANCE_SCENARIOS.items():
        print(f"\nğŸ§ª æµ‹è¯•åœºæ™¯: {scenario_name}")
        print(f"   æè¿°: {scenario_config['description']}")
        
        config = {
            'max_steps': steps,
            'init_kp': 0.5,
            'init_kd': 0.1,
            'kp_range': (0.1, 2.0),
            'kd_range': (0.01, 0.5),
            'disturbance': scenario_config
        }
        
        try:
            env = LaikagoAdaptiveEnv(config=config, gui=gui, use_meta_learning=True)
            obs, _ = env.reset()
            
            total_reward = 0
            for step in range(steps):
                action = env.action_space.sample() * 0.01  # å°å¹…éšæœºåŠ¨ä½œ
                obs, reward, terminated, truncated, info = env.step(action)
                total_reward += reward
                
                if step % 1000 == 0:
                    print(f"   Step {step}: reward={reward:.2f}, Kp={info['current_kp']:.3f}")
                
                if terminated or truncated:
                    print(f"   âš ï¸  Episodeç»“æŸäºstep {step}")
                    break
            
            env.close()
            print(f"   âœ… æµ‹è¯•å®Œæˆï¼æ€»å¥–åŠ±: {total_reward:.2f}")
            
        except Exception as e:
            print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
            continue
    
    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰åœºæ™¯æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================
if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='å¤šåœºæ™¯æ‰°åŠ¨è®­ç»ƒ')
    parser.add_argument('--mode', type=str, default='train', 
                       choices=['train', 'test'],
                       help='è®­ç»ƒæˆ–æµ‹è¯•æ¨¡å¼')
    parser.add_argument('--scenarios', type=str, nargs='+',
                       default=['random_force', 'payload', 'terrain', 'param_uncertainty'],
                       help='è¦è®­ç»ƒçš„åœºæ™¯')
    parser.add_argument('--timesteps', type=int, default=500000,
                       help='æ¯ä¸ªåœºæ™¯çš„è®­ç»ƒæ­¥æ•°')
    parser.add_argument('--n_envs', type=int, default=4,
                       help='å¹¶è¡Œç¯å¢ƒæ•°é‡')
    parser.add_argument('--gpu', action='store_true',
                       help='ä½¿ç”¨GPUè®­ç»ƒ')
    parser.add_argument('--gui', action='store_true',
                       help='æµ‹è¯•æ—¶æ˜¾ç¤ºGUI')
    
    args = parser.parse_args()
    
    if args.mode == 'train':
        results = train_all_scenarios(
            scenarios=args.scenarios,
            total_timesteps=args.timesteps,
            n_envs=args.n_envs,
            use_gpu=args.gpu
        )
    
    elif args.mode == 'test':
        quick_test_all_scenarios(steps=5000, gui=args.gui)

