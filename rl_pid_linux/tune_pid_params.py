"""
ğŸ”§ PIDå‚æ•°è‡ªåŠ¨ä¼˜åŒ–è„šæœ¬

ç›®æ ‡ï¼šæ‰¾åˆ°ä½¿è·Ÿè¸ªè¯¯å·®æœ€å°ä¸”ç¨³å®šçš„PIDå‚æ•°

è¯„ä¼°æ ‡å‡†ï¼š
1. è·Ÿè¸ªè¯¯å·®ï¼ˆä¸»è¦ï¼‰
2. æ§åˆ¶åŠ›çŸ©å¹³æ»‘åº¦ï¼ˆé¿å…éœ‡è¡ï¼‰
3. ç¨³å®šæ€§ï¼ˆé¿å…å‘æ•£ï¼‰
"""

import yaml
import numpy as np
from envs.franka_env import FrankaRLPIDEnv
from tqdm import tqdm
import matplotlib.pyplot as plt
from scipy.optimize import minimize
import json

def evaluate_pid_params(Kp_scale, Ki_scale, Kd_scale, config_template, n_steps=2000, verbose=False):
    """
    è¯„ä¼°ä¸€ç»„PIDå‚æ•°çš„æ€§èƒ½
    
    å‚æ•°ï¼š
        Kp_scale, Ki_scale, Kd_scale: ç›¸å¯¹äºåŸºå‡†å€¼çš„ç¼©æ”¾å› å­
        config_template: é…ç½®æ¨¡æ¿
        n_steps: è¯„ä¼°æ­¥æ•°
    
    è¿”å›ï¼š
        score: ç»¼åˆè¯„åˆ†ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        metrics: è¯¦ç»†æŒ‡æ ‡
    """
    # åŸºå‡†PIDå‚æ•°ï¼ˆç»éªŒå€¼ï¼‰
    Kp_base = np.array([100.0, 100.0, 100.0, 100.0, 50.0, 30.0, 20.0])
    Ki_base = np.array([0.5, 0.5, 0.5, 0.5, 0.2, 0.1, 0.1])
    Kd_base = np.array([10.0, 10.0, 10.0, 10.0, 5.0, 3.0, 2.0])
    
    # åº”ç”¨ç¼©æ”¾å› å­
    Kp = Kp_base * Kp_scale
    Ki = Ki_base * Ki_scale
    Kd = Kd_base * Kd_scale
    
    # åˆ›å»ºé…ç½®
    config = config_template.copy()
    config['pid_params']['Kp'] = Kp.tolist()
    config['pid_params']['Ki'] = Ki.tolist()
    config['pid_params']['Kd'] = Kd.tolist()
    config['pid_params']['enable_gravity_compensation'] = False
    
    # åˆ›å»ºç¯å¢ƒ
    try:
        env = FrankaRLPIDEnv(config, gui=False)
    except Exception as e:
        if verbose:
            print(f"  âŒ ç¯å¢ƒåˆ›å»ºå¤±è´¥: {e}")
        return 1e6, None  # è¿”å›æå¤§æƒ©ç½š
    
    # è¿è¡Œä»¿çœŸ
    obs, _ = env.reset()
    errors = []
    tau_pid_list = []
    
    try:
        for step in range(n_steps):
            # çº¯PIDæ§åˆ¶ï¼ˆaction=0ï¼‰
            action = np.zeros(7, dtype=np.float32)
            obs, reward, terminated, truncated, info = env.step(action)
            
            errors.append(info['err_norm'])
            tau_pid_list.append(info.get('tau_pid', np.zeros(7)))
            
            # æ£€æŸ¥ç¨³å®šæ€§
            if info['err_norm'] > 3.0:  # è¯¯å·®>3å¼§åº¦è®¤ä¸ºä¸ç¨³å®š
                if verbose:
                    print(f"  âš ï¸ ç¬¬{step}æ­¥ä¸ç¨³å®šï¼Œè¯¯å·®={info['err_norm']:.2f}")
                env.close()
                return 1e6, None  # ä¸ç¨³å®šï¼Œè¿”å›æå¤§æƒ©ç½š
                
    except Exception as e:
        if verbose:
            print(f"  âŒ ä»¿çœŸå¤±è´¥: {e}")
        env.close()
        return 1e6, None
    
    env.close()
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    errors = np.array(errors)
    tau_pid_array = np.array(tau_pid_list)
    
    # è·³è¿‡å‰100æ­¥ï¼ˆé¢„çƒ­æœŸï¼‰
    errors_stable = errors[100:]
    tau_pid_stable = tau_pid_array[100:]
    
    # 1. è·Ÿè¸ªè¯¯å·®ï¼ˆä¸»è¦æŒ‡æ ‡ï¼Œæƒé‡æœ€å¤§ï¼‰
    mean_error = np.mean(errors_stable)
    max_error = np.max(errors_stable)
    std_error = np.std(errors_stable)
    
    # 2. æ§åˆ¶åŠ›çŸ©å¹³æ»‘åº¦ï¼ˆé¿å…éœ‡è¡ï¼‰
    tau_diff = np.diff(tau_pid_stable, axis=0)
    tau_smoothness = np.mean(np.abs(tau_diff))  # åŠ›çŸ©å˜åŒ–ç‡
    
    # 3. æ§åˆ¶åŠ›çŸ©å¹…å€¼
    tau_magnitude = np.mean(np.abs(tau_pid_stable))
    
    # ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå’Œï¼‰
    score = (
        10.0 * mean_error +      # å¹³å‡è¯¯å·®ï¼ˆæœ€é‡è¦ï¼‰
        2.0 * max_error +         # æœ€å¤§è¯¯å·®
        1.0 * std_error +         # è¯¯å·®æ³¢åŠ¨
        0.01 * tau_smoothness +   # åŠ›çŸ©å¹³æ»‘åº¦
        0.001 * tau_magnitude     # åŠ›çŸ©å¹…å€¼
    )
    
    metrics = {
        'mean_error': float(mean_error),
        'max_error': float(max_error),
        'std_error': float(std_error),
        'tau_smoothness': float(tau_smoothness),
        'tau_magnitude': float(tau_magnitude),
        'score': float(score),
        'Kp': [float(x) for x in Kp],
        'Ki': [float(x) for x in Ki],
        'Kd': [float(x) for x in Kd],
        'Kp_scale': float(Kp_scale),
        'Ki_scale': float(Ki_scale),
        'Kd_scale': float(Kd_scale)
    }
    
    if verbose:
        print(f"  è¯¯å·®: {mean_error:.4f}Â±{std_error:.4f} (æœ€å¤§{max_error:.4f})")
        print(f"  å¹³æ»‘åº¦: {tau_smoothness:.2f}, åŠ›çŸ©: {tau_magnitude:.2f}")
        print(f"  ç»¼åˆå¾—åˆ†: {score:.2f}")
    
    return score, metrics


def grid_search(config_template, n_steps=2000):
    """ç½‘æ ¼æœç´¢PIDå‚æ•°"""
    print("=" * 70)
    print("ğŸ” æ–¹æ³•1: ç½‘æ ¼æœç´¢")
    print("=" * 70)
    
    # æœç´¢ç©ºé—´ï¼ˆç›¸å¯¹äºåŸºå‡†å€¼çš„ç¼©æ”¾å› å­ï¼‰
    Kp_scales = [0.5, 1.0, 2.0, 3.0, 4.0]
    Ki_scales = [0.1, 0.5, 1.0, 2.0]
    Kd_scales = [0.5, 1.0, 2.0, 3.0]
    
    total_tests = len(Kp_scales) * len(Ki_scales) * len(Kd_scales)
    print(f"æœç´¢ç©ºé—´: {total_tests}ç»„å‚æ•°")
    print()
    
    best_score = float('inf')
    best_metrics = None
    all_results = []
    
    with tqdm(total=total_tests, desc="ç½‘æ ¼æœç´¢è¿›åº¦") as pbar:
        for Kp_s in Kp_scales:
            for Ki_s in Ki_scales:
                for Kd_s in Kd_scales:
                    score, metrics = evaluate_pid_params(
                        Kp_s, Ki_s, Kd_s, 
                        config_template, 
                        n_steps=n_steps,
                        verbose=False
                    )
                    
                    if metrics is not None:
                        all_results.append(metrics)
                        
                        if score < best_score:
                            best_score = score
                            best_metrics = metrics
                            tqdm.write(f"âœ¨ æ–°æœ€ä¼˜: KpÃ—{Kp_s:.1f}, KiÃ—{Ki_s:.1f}, KdÃ—{Kd_s:.1f} "
                                     f"â†’ è¯¯å·®={metrics['mean_error']:.4f}, å¾—åˆ†={score:.2f}")
                    
                    pbar.update(1)
    
    return best_metrics, all_results


def bayesian_optimization(config_template, n_iterations=50, n_steps=2000):
    """è´å¶æ–¯ä¼˜åŒ–ï¼ˆä½¿ç”¨ç®€å•çš„éšæœºæœç´¢ + å±€éƒ¨ä¼˜åŒ–ï¼‰"""
    print("\n" + "=" * 70)
    print("ğŸ¯ æ–¹æ³•2: è´å¶æ–¯ä¼˜åŒ–ï¼ˆå±€éƒ¨ç²¾ç»†æœç´¢ï¼‰")
    print("=" * 70)
    
    # ä»ç½‘æ ¼æœç´¢çš„æœ€ä¼˜ç»“æœé™„è¿‘å¼€å§‹
    print("åŸºäºç½‘æ ¼æœç´¢ç»“æœï¼Œåœ¨æœ€ä¼˜ç‚¹é™„è¿‘è¿›è¡Œç²¾ç»†æœç´¢...")
    print()
    
    def objective(x):
        """ä¼˜åŒ–ç›®æ ‡å‡½æ•°"""
        Kp_s, Ki_s, Kd_s = x
        # å‚æ•°çº¦æŸ
        if Kp_s < 0.1 or Kp_s > 10.0:
            return 1e6
        if Ki_s < 0.01 or Ki_s > 5.0:
            return 1e6
        if Kd_s < 0.1 or Kd_s > 10.0:
            return 1e6
        
        score, _ = evaluate_pid_params(Kp_s, Ki_s, Kd_s, config_template, n_steps=n_steps)
        return score
    
    # ä½¿ç”¨Nelder-Meadç®—æ³•ï¼ˆä¸éœ€è¦æ¢¯åº¦ï¼‰
    from scipy.optimize import minimize
    
    # å¤šæ¬¡éšæœºåˆå§‹åŒ–ï¼Œé€‰æ‹©æœ€å¥½çš„
    best_result = None
    best_score_global = float('inf')
    
    # å€™é€‰åˆå§‹ç‚¹ï¼ˆåŸºäºç»éªŒï¼‰
    initial_points = [
        [2.0, 0.5, 2.0],   # ä¸­ç­‰å¢ç›Š
        [3.0, 1.0, 2.0],   # é«˜Kp
        [4.0, 0.5, 3.0],   # å¾ˆé«˜Kp
        [2.0, 0.1, 1.0],   # ä½Ki
        [3.0, 0.5, 1.5],   # å¹³è¡¡å‹
    ]
    
    for i, x0 in enumerate(initial_points):
        print(f"\nä¼˜åŒ–å°è¯• {i+1}/{len(initial_points)}: åˆå§‹ç‚¹ KpÃ—{x0[0]}, KiÃ—{x0[1]}, KdÃ—{x0[2]}")
        
        result = minimize(
            objective, 
            x0=x0,
            method='Nelder-Mead',
            options={'maxiter': 30, 'disp': False}
        )
        
        if result.fun < best_score_global:
            best_score_global = result.fun
            best_result = result
            print(f"  âœ¨ æ–°æœ€ä¼˜å¾—åˆ†: {result.fun:.2f}")
    
    # è·å–æœ€ä¼˜å‚æ•°çš„è¯¦ç»†æŒ‡æ ‡
    Kp_opt, Ki_opt, Kd_opt = best_result.x
    _, best_metrics = evaluate_pid_params(
        Kp_opt, Ki_opt, Kd_opt, 
        config_template, 
        n_steps=n_steps,
        verbose=True
    )
    
    return best_metrics


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸ”§ PIDå‚æ•°è‡ªåŠ¨ä¼˜åŒ–")
    print("=" * 70)
    print()
    
    # åŠ è½½é…ç½®æ¨¡æ¿
    with open('configs/stage1_final.yaml', 'r') as f:
        config_template = yaml.safe_load(f)
    
    print(f"è½¨è¿¹ç±»å‹: {config_template['trajectory']['type']}")
    print(f"è½¨è¿¹é€Ÿåº¦: {config_template['trajectory']['speed']} rad/s")
    print(f"è½¨è¿¹å¹…åº¦: {config_template['trajectory']['amplitude']} rad")
    print()
    
    # é˜¶æ®µ1: ç½‘æ ¼æœç´¢ï¼ˆç²—ç•¥æœç´¢ï¼‰
    best_grid, all_results = grid_search(config_template, n_steps=1000)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š ç½‘æ ¼æœç´¢æœ€ä¼˜ç»“æœ")
    print("=" * 70)
    print(f"Kpç¼©æ”¾: {best_grid['Kp_scale']:.2f}")
    print(f"Kiç¼©æ”¾: {best_grid['Ki_scale']:.2f}")
    print(f"Kdç¼©æ”¾: {best_grid['Kd_scale']:.2f}")
    print(f"\nå®é™…PIDå‚æ•°:")
    print(f"Kp: {np.array(best_grid['Kp'])}")
    print(f"Ki: {np.array(best_grid['Ki'])}")
    print(f"Kd: {np.array(best_grid['Kd'])}")
    print(f"\næ€§èƒ½æŒ‡æ ‡:")
    print(f"å¹³å‡è¯¯å·®: {best_grid['mean_error']:.4f} å¼§åº¦ ({np.rad2deg(best_grid['mean_error']):.2f}åº¦)")
    print(f"æœ€å¤§è¯¯å·®: {best_grid['max_error']:.4f} å¼§åº¦ ({np.rad2deg(best_grid['max_error']):.2f}åº¦)")
    print(f"è¯¯å·®æ ‡å‡†å·®: {best_grid['std_error']:.4f}")
    
    # é˜¶æ®µ2: å±€éƒ¨ç²¾ç»†æœç´¢
    # ä»¥ç½‘æ ¼æœç´¢æœ€ä¼˜ç‚¹ä¸ºä¸­å¿ƒ
    config_template['pid_params']['Kp'] = best_grid['Kp']
    config_template['pid_params']['Ki'] = best_grid['Ki']
    config_template['pid_params']['Kd'] = best_grid['Kd']
    
    best_bayes = bayesian_optimization(config_template, n_iterations=50, n_steps=2000)
    
    print("\n" + "=" * 70)
    print("ğŸ† æœ€ç»ˆä¼˜åŒ–ç»“æœ")
    print("=" * 70)
    print(f"\næœ€ä¼˜PIDå‚æ•°:")
    print(f"Kp: {np.array(best_bayes['Kp'])}")
    print(f"Ki: {np.array(best_bayes['Ki'])}")
    print(f"Kd: {np.array(best_bayes['Kd'])}")
    print(f"\næ€§èƒ½æŒ‡æ ‡:")
    print(f"å¹³å‡è¯¯å·®: {best_bayes['mean_error']:.4f} å¼§åº¦ ({np.rad2deg(best_bayes['mean_error']):.2f}åº¦)")
    print(f"æœ€å¤§è¯¯å·®: {best_bayes['max_error']:.4f} å¼§åº¦ ({np.rad2deg(best_bayes['max_error']):.2f}åº¦)")
    print(f"è¯¯å·®æ ‡å‡†å·®: {best_bayes['std_error']:.4f}")
    print(f"ç»¼åˆå¾—åˆ†: {best_bayes['score']:.2f}")
    
    # ä¿å­˜ç»“æœ
    output_file = 'pid_tuning_results.json'
    with open(output_file, 'w') as f:
        json.dump({
            'best_params': best_bayes,
            'grid_search_best': best_grid,
            'all_grid_results': all_results
        }, f, indent=2)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # å¯è§†åŒ–å¯¹æ¯”
    print("\nç”Ÿæˆå¯¹æ¯”å›¾...")
    visualize_results(all_results, best_bayes)
    print("âœ… å›¾è¡¨å·²ä¿å­˜åˆ°: pid_tuning_visualization.png")
    
    # ç”Ÿæˆé…ç½®æ–‡ä»¶
    print("\nç”Ÿæˆä¼˜åŒ–åçš„é…ç½®æ–‡ä»¶...")
    config_optimized = config_template.copy()
    config_optimized['pid_params']['Kp'] = best_bayes['Kp']
    config_optimized['pid_params']['Ki'] = best_bayes['Ki']
    config_optimized['pid_params']['Kd'] = best_bayes['Kd']
    
    with open('configs/stage1_optimized.yaml', 'w') as f:
        yaml.dump(config_optimized, f, default_flow_style=False, sort_keys=False)
    
    print("âœ… ä¼˜åŒ–é…ç½®å·²ä¿å­˜åˆ°: configs/stage1_optimized.yaml")
    
    print("\n" + "=" * 70)
    print("ğŸ¯ ä¸‹ä¸€æ­¥ï¼šä½¿ç”¨ä¼˜åŒ–åçš„PIDå‚æ•°è®­ç»ƒRL")
    print("=" * 70)
    print("python training/train_ppo.py --config configs/stage1_optimized.yaml")


def visualize_results(all_results, best_result):
    """å¯è§†åŒ–è°ƒå‚ç»“æœ"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # æå–æ•°æ®
    mean_errors = [r['mean_error'] for r in all_results]
    max_errors = [r['max_error'] for r in all_results]
    Kp_scales = [r['Kp_scale'] for r in all_results]
    Ki_scales = [r['Ki_scale'] for r in all_results]
    Kd_scales = [r['Kd_scale'] for r in all_results]
    scores = [r['score'] for r in all_results]
    
    # å­å›¾1: è¯¯å·® vs Kpç¼©æ”¾
    axes[0, 0].scatter(Kp_scales, mean_errors, alpha=0.6, s=50, c=scores, cmap='RdYlGn_r')
    axes[0, 0].scatter(best_result['Kp_scale'], best_result['mean_error'], 
                      color='red', s=200, marker='*', label='æœ€ä¼˜', zorder=5)
    axes[0, 0].set_xlabel('Kpç¼©æ”¾å› å­', fontsize=12)
    axes[0, 0].set_ylabel('å¹³å‡è¯¯å·® (å¼§åº¦)', fontsize=12)
    axes[0, 0].set_title('è¯¯å·® vs Kpç¼©æ”¾', fontsize=14, fontweight='bold')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # å­å›¾2: è¯¯å·® vs Kiç¼©æ”¾
    axes[0, 1].scatter(Ki_scales, mean_errors, alpha=0.6, s=50, c=scores, cmap='RdYlGn_r')
    axes[0, 1].scatter(best_result['Ki_scale'], best_result['mean_error'], 
                      color='red', s=200, marker='*', label='æœ€ä¼˜', zorder=5)
    axes[0, 1].set_xlabel('Kiç¼©æ”¾å› å­', fontsize=12)
    axes[0, 1].set_ylabel('å¹³å‡è¯¯å·® (å¼§åº¦)', fontsize=12)
    axes[0, 1].set_title('è¯¯å·® vs Kiç¼©æ”¾', fontsize=14, fontweight='bold')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # å­å›¾3: è¯¯å·® vs Kdç¼©æ”¾
    axes[1, 0].scatter(Kd_scales, mean_errors, alpha=0.6, s=50, c=scores, cmap='RdYlGn_r')
    axes[1, 0].scatter(best_result['Kd_scale'], best_result['mean_error'], 
                      color='red', s=200, marker='*', label='æœ€ä¼˜', zorder=5)
    axes[1, 0].set_xlabel('Kdç¼©æ”¾å› å­', fontsize=12)
    axes[1, 0].set_ylabel('å¹³å‡è¯¯å·® (å¼§åº¦)', fontsize=12)
    axes[1, 0].set_title('è¯¯å·® vs Kdç¼©æ”¾', fontsize=14, fontweight='bold')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # å­å›¾4: ç»¼åˆå¾—åˆ†åˆ†å¸ƒ
    axes[1, 1].hist(scores, bins=20, alpha=0.7, edgecolor='black')
    axes[1, 1].axvline(best_result['score'], color='red', linestyle='--', 
                      linewidth=2, label=f'æœ€ä¼˜å¾—åˆ†: {best_result["score"]:.2f}')
    axes[1, 1].set_xlabel('ç»¼åˆå¾—åˆ†', fontsize=12)
    axes[1, 1].set_ylabel('é¢‘æ•°', fontsize=12)
    axes[1, 1].set_title('å¾—åˆ†åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig('pid_tuning_visualization.png', dpi=150, bbox_inches='tight')
    plt.close()


if __name__ == '__main__':
    main()

