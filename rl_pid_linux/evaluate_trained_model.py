"""
è¯„ä¼°è®­ç»ƒå¥½çš„RL+PIDæ¨¡å‹
"""

import yaml
import numpy as np
import argparse
from stable_baselines3 import PPO
from envs.franka_env import FrankaRLPIDEnv
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# è§£æå‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser(description='è¯„ä¼°RL+PIDæ¨¡å‹')
parser.add_argument('--gui', action='store_true', help='å¯ç”¨PyBulletå¯è§†åŒ–')
parser.add_argument('--steps', type=int, default=10000, help='è¯„ä¼°æ­¥æ•°')
parser.add_argument('--slow', action='store_true', help='æ…¢é€Ÿæ’­æ”¾ï¼ˆGUIæ¨¡å¼ï¼‰')
parser.add_argument('--model', type=str, default='./logs/rl_pid_ppo_final', help='æ¨¡å‹è·¯å¾„ï¼ˆä¸å«.zipï¼‰')
parser.add_argument('--config', type=str, default='configs/stage1_final.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
args = parser.parse_args()

# åŠ è½½é…ç½®
with open(args.config, 'r') as f:
    config = yaml.safe_load(f)

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
model_path = args.model.replace('.zip', '')  # ç§»é™¤.zipåç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
model = PPO.load(model_path)
print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {args.config}")

if args.gui:
    print("\nğŸ¬ å¯åŠ¨å¯è§†åŒ–æ¨¡å¼...")
    print("   å¯è§†åŒ–çª—å£å°†æ˜¾ç¤ºæœºæ¢°è‡‚è¿åŠ¨")
    if args.slow:
        print("   æ…¢é€Ÿæ’­æ”¾æ¨¡å¼å·²å¯ç”¨")
    print("   å…³é—­çª—å£å¯åœæ­¢è¯„ä¼°\n")

# åˆ›å»ºç¯å¢ƒ
env = FrankaRLPIDEnv(config, gui=args.gui)

import time

print("\n" + "=" * 70)
print("æµ‹è¯•1ï¼šçº¯PIDåŸºçº¿ï¼ˆaction=0ï¼‰")
print("=" * 70)

if args.gui:
    print("ğŸ¬ æ­£åœ¨å¯è§†åŒ–çº¯PIDæ§åˆ¶...")

obs, _ = env.reset()
total_reward_pid = 0
errors_pid = []
times = []

for step in range(args.steps):
    action = np.zeros(7, dtype=np.float32)
    obs, reward, terminated, truncated, info = env.step(action)
    total_reward_pid += reward
    errors_pid.append(info['err_norm'])
    times.append(step * 0.001)
    
    # æ…¢é€Ÿæ’­æ”¾
    if args.gui and args.slow:
        time.sleep(0.01)  # 10å€æ…¢é€Ÿ
    
    if step % 2000 == 0:
        print(f"Step {step:5d}: err={info['err_norm']:.4f}, reward={reward:6.2f}")

print(f"\nçº¯PID æ€»å¥–åŠ±: {total_reward_pid:.1f}")
print(f"çº¯PID å¹³å‡è¯¯å·®: {np.mean(errors_pid):.4f}å¼§åº¦ ({np.mean(errors_pid)*57.3:.1f}åº¦)")
print(f"çº¯PID ä¸­ä½è¯¯å·®: {np.median(errors_pid):.4f}å¼§åº¦")
print(f"çº¯PID æœ€å¤§è¯¯å·®: {np.max(errors_pid):.4f}å¼§åº¦")

print("\n" + "=" * 70)
print("æµ‹è¯•2ï¼šRL+PIDï¼ˆä½¿ç”¨è®­ç»ƒçš„ç­–ç•¥ï¼‰")
print("=" * 70)

if args.gui:
    print("ğŸ¬ æ­£åœ¨å¯è§†åŒ–RL+PIDæ§åˆ¶...")
    print("   è§‚å¯Ÿæœºæ¢°è‡‚å¦‚ä½•é€šè¿‡RLè¡¥å¿æ”¹å–„è·Ÿè¸ªæ€§èƒ½\n")

obs, _ = env.reset()
total_reward_rl = 0
errors_rl = []
actions_rl = []
delta_taus = []

for step in range(args.steps):
    action, _ = model.predict(obs, deterministic=True)
    obs, reward, terminated, truncated, info = env.step(action)
    total_reward_rl += reward
    errors_rl.append(info['err_norm'])
    actions_rl.append(action.copy())
    delta_taus.append(info.get('delta_tau', np.zeros(7)))
    
    # æ…¢é€Ÿæ’­æ”¾
    if args.gui and args.slow:
        time.sleep(0.01)  # 10å€æ…¢é€Ÿ
    
    if step % 2000 == 0:
        print(f"Step {step:5d}: err={info['err_norm']:.4f}, reward={reward:6.2f}, action_norm={np.linalg.norm(action):.4f}")

print(f"\nRL+PID æ€»å¥–åŠ±: {total_reward_rl:.1f}")
print(f"RL+PID å¹³å‡è¯¯å·®: {np.mean(errors_rl):.4f}å¼§åº¦ ({np.mean(errors_rl)*57.3:.1f}åº¦)")
print(f"RL+PID ä¸­ä½è¯¯å·®: {np.median(errors_rl):.4f}å¼§åº¦")
print(f"RL+PID æœ€å¤§è¯¯å·®: {np.max(errors_rl):.4f}å¼§åº¦")

print("\n" + "=" * 70)
print("æ€§èƒ½å¯¹æ¯”")
print("=" * 70)

reward_improvement = total_reward_rl - total_reward_pid
error_reduction = np.mean(errors_pid) - np.mean(errors_rl)
percent_improvement = (reward_improvement / abs(total_reward_pid)) * 100

print(f"å¥–åŠ±æ”¹å–„: {reward_improvement:+.1f} ({percent_improvement:+.2f}%)")
print(f"è¯¯å·®é™ä½: {error_reduction:.4f}å¼§åº¦ ({error_reduction*57.3:.2f}åº¦)")
print(f"è¯¯å·®æ”¹å–„ç‡: {(error_reduction / np.mean(errors_pid) * 100):.2f}%")

actions_rl = np.array(actions_rl)
delta_taus = np.array(delta_taus)
print(f"\nRLè¡¥å¿ç»Ÿè®¡:")
print(f"  å¹³å‡actionèŒƒæ•°: {np.mean(np.linalg.norm(actions_rl, axis=1)):.4f}")
print(f"  å¹³å‡delta_tauèŒƒæ•°: {np.mean(np.linalg.norm(delta_taus, axis=1)):.4f} Nm")
print(f"  æœ€å¤§delta_tauèŒƒæ•°: {np.max(np.linalg.norm(delta_taus, axis=1)):.4f} Nm")

env.close()

# ç»˜åˆ¶å¯¹æ¯”å›¾
fig, axes = plt.subplots(2, 1, figsize=(12, 8))

# è¯¯å·®å¯¹æ¯”
axes[0].plot(times, errors_pid, 'b-', label=f'çº¯PID (å¹³å‡={np.mean(errors_pid):.4f})', alpha=0.7)
axes[0].plot(times, errors_rl, 'r-', label=f'RL+PID (å¹³å‡={np.mean(errors_rl):.4f})', alpha=0.7)
axes[0].set_xlabel('æ—¶é—´ (s)', fontsize=12)
axes[0].set_ylabel('è·Ÿè¸ªè¯¯å·® (å¼§åº¦)', fontsize=12)
axes[0].set_title('è·Ÿè¸ªè¯¯å·®å¯¹æ¯”', fontsize=14, fontweight='bold')
axes[0].legend(fontsize=11)
axes[0].grid(True, alpha=0.3)

# RLè¡¥å¿åŠ›çŸ©
delta_tau_norms = np.linalg.norm(delta_taus, axis=1)
axes[1].plot(times, delta_tau_norms, 'g-', label=f'RLè¡¥å¿åŠ›çŸ©èŒƒæ•° (å¹³å‡={np.mean(delta_tau_norms):.3f} Nm)')
axes[1].set_xlabel('æ—¶é—´ (s)', fontsize=12)
axes[1].set_ylabel('è¡¥å¿åŠ›çŸ©èŒƒæ•° (Nm)', fontsize=12)
axes[1].set_title('RLè¡¥å¿åŠ›çŸ©', fontsize=14, fontweight='bold')
axes[1].legend(fontsize=11)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('evaluation_results.png', dpi=150, bbox_inches='tight')
print(f"\nâœ… å¯¹æ¯”å›¾å·²ä¿å­˜è‡³: evaluation_results.png")

print("\n" + "=" * 70)
print("è¯„ä¼°å®Œæˆ")
print("=" * 70)

