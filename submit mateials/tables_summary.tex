\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{longtable}
\usepackage{bm}
\usepackage[section]{placeins}

% Define \tblwidth for compatibility
\newlength{\tblwidth}
\setlength{\tblwidth}{\linewidth}

% Reduce spacing between floats
\setlength{\floatsep}{8pt plus 2pt minus 2pt}
\setlength{\textfloatsep}{12pt plus 2pt minus 4pt}
\setlength{\intextsep}{8pt plus 2pt minus 2pt}

% Adjust spacing for sections and subsections
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{12pt plus 4pt minus 2pt}{6pt plus 2pt minus 2pt}
\titlespacing*{\subsection}{0pt}{10pt plus 3pt minus 2pt}{4pt plus 2pt minus 2pt}

\begin{document}

\title{Summary of All Tables\\[0.5em]
{\large Adaptive PID Control for Robotic Systems via Hierarchical Meta-Learning and Reinforcement Learning with Physics-Based Data Augmentation}}
\date{}
\maketitle

\tableofcontents
\newpage

%=============================================================================
\section{Main Results Tables}
%=============================================================================

\subsection{Cross-Platform Performance}

\noindent
\begin{table}[!h]
\caption{Performance on Franka Panda (9-DOF)}
\label{tab:franka_results}
\centering
\begin{tabular}{llll}
\toprule
\textbf{Metric} & \textbf{Meta-PID} & \textbf{Meta-PID+RL} & \textbf{Improv.} \\
\midrule
MAE (°) & 7.51 & \textbf{6.26} & +16.6\% \\
RMSE (°) & 29.32 & \textbf{25.45} & +13.2\% \\
Max Error (°) & 48.49 & \textbf{42.12} & +13.1\% \\
Std Dev (°) & 4.94 & \textbf{4.40} & +10.9\% \\
\bottomrule
\end{tabular}
\end{table}

\vspace{-0.3cm}

\begin{table}[!h]
\caption{Performance on Laikago (12-DOF)}
\label{tab:laikago_results}
\centering
\begin{tabular}{llll}
\toprule
\textbf{Metric} & \textbf{Meta-PID} & \textbf{Meta-PID+RL} & \textbf{Improv.} \\
\midrule
MAE (°) & 5.91 & \textbf{5.91} & +0.0\% \\
RMSE (°) & 29.70 & \textbf{29.29} & +1.4\% \\
Max Error (°) & 53.09 & \textbf{50.44} & +5.0\% \\
Std Dev (°) & 5.25 & \textbf{5.18} & +1.3\% \\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier

\subsection{Per-Joint Analysis}

\begin{table}[!h]
\caption{Per-Joint Tracking Error Comparison Across Platforms}
\label{tab:per_joint_error}
\centering
\small
\begin{tabular}{lllll}
\toprule
\textbf{Robot} & \textbf{Joint} & \textbf{Pure Meta-PID (°)} & \textbf{Meta-PID+RL (°)} & \textbf{Improv.} \\
\midrule
Franka Panda    & J1     &   2.57 &   2.26 & +12.2\% \\
                & J2     &  12.36 &   2.42 & \textbf{+80.4\%} \\
                & J3     &   4.10 &   3.87 &  +5.7\% \\
                & J4     &   6.78 &   6.49 &  +4.3\% \\
                & J5     &   5.41 &   5.32 &  +1.6\% \\
                & J6     &   4.31 &   4.19 &  +2.8\% \\
                & J7     &  11.45 &  11.26 &  +1.6\% \\
                & J8     &  10.23 &  10.19 &  +0.3\% \\
                & J9     &  10.36 &  10.33 &  +0.3\% \\
\midrule
\textit{Franka Panda Avg} & &   7.51 &   6.26 & +16.6\% \\
\midrule
Laikago         & J1     &   1.38 &   1.52 &  -9.6\% \\
                & J2     &   6.16 &   5.96 &  +3.3\% \\
                & J3     &  10.45 &  10.34 &  +1.0\% \\
                & J4     &   1.36 &   1.45 &  -6.8\% \\
                & J5     &   5.70 &   5.96 &  -4.5\% \\
                & J6     &  10.54 &  10.33 &  +2.0\% \\
                & J7     &   1.36 &   1.41 &  -3.1\% \\
                & J8     &   5.35 &   5.86 &  -9.6\% \\
                & J9     &  10.44 &  10.36 &  +0.8\% \\
                & J10    &   1.35 &   1.44 &  -6.7\% \\
                & J11    &   6.41 &   5.92 &  +7.7\% \\
                & J12    &  10.44 &  10.39 &  +0.5\% \\
\midrule
\textit{Laikago Avg} & &   5.91 &   5.91 &  +0.0\% \\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier

\subsection{Robustness Analysis}

\begin{table}[!h]
\caption{Robustness Analysis (Franka Panda, MAE in °, Representative Seed 51, 20 Episodes)}
\label{tab:robustness}
\centering
\begin{tabular}{llll}
\toprule
\textbf{Disturbance} & \textbf{Meta-PID} & \textbf{Meta-PID+RL} & \textbf{Improv.} \\
\midrule
No Disturbance & 7.51 & \textbf{6.26} & +16.6\% \\
Random Force & 25.77 & \textbf{25.01} & +2.9\% \\
Payload Var. & 67.12 & \textbf{61.68} & +8.1\% \\
\textbf{Param. Uncert.} & 35.90 & \textbf{29.01} & \textbf{+19.2\%} \\
Mixed Dist. & 88.00 & \textbf{82.37} & +6.4\% \\
\midrule
\textit{Average} & \textit{49.09} & \textit{44.59} & \textit{+10.0\%} \\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier

\subsection{Method Comparison}

\begin{table}[!h]
\caption{Method Comparison: Proposed Approach vs. Traditional Methods}
\label{tab:method_advantages}
\centering
\begin{tabular}{lll}
\toprule
\textbf{Aspect} & \textbf{Traditional Methods} & \textbf{Our Method} \\
\midrule
Tuning Time & Hours to days & \textbf{10 minutes} \\
Expert Required & Yes (manual tuning) & \textbf{No (automated)} \\
Cross-Platform & Per-robot tuning & \textbf{Yes (9-12 DOF)} \\
Online Adaptation & No & \textbf{Yes (+19.2\%)} \\
Sample Efficiency & N/A (manual) & \textbf{1M steps} \\
Disturbance Handling & Fixed parameters & \textbf{Adaptive} \\
\bottomrule
\end{tabular}
\end{table}

%=============================================================================
\section{Ablation Studies}
%=============================================================================

\begin{table}[!h]
\caption{Ablation: Data Augmentation Impact}
\label{tab:ablation_aug}
\centering
\begin{tabular}{lll}
\toprule
\textbf{Training Data} & \textbf{Samples} & \textbf{Prediction Error (\%)} \\
\midrule
Base robots only & 3 & 31.2 \\
+ Augmentation & 303 & 3.33 \\
\bottomrule
\end{tabular}
\end{table}

%=============================================================================
\section{Appendix: Hyperparameters and Configuration}
%=============================================================================

\subsection{Meta-Learning Network}

\begin{table}[!h]
\caption{Meta-Learning Network Hyperparameters}
\label{tab:meta_hyperparams}
\centering
\small
\begin{tabular}{p{0.42\linewidth}p{0.48\linewidth}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
\multicolumn{2}{l}{\textit{Network Architecture}} \\
Input dimension & 10 \\
Encoder layers & 256 + 256 + LayerNorm \\
Hidden layer & 128 + LayerNorm \\
Output dimension & 7 \\
Output activation & Sigmoid \\
\midrule
\multicolumn{2}{l}{\textit{Training Configuration}} \\
Optimizer & Adam \\
Learning rate & 0.001 \\
Weight decay & $10^{-5}$ \\
Batch size & 32 \\
Max epochs & 500 \\
Early stopping & 50 epochs \\
Loss function & Weighted MSE \\
\midrule
\multicolumn{2}{l}{\textit{Data Split}} \\
Training samples & 185 (80\%) \\
Validation samples & 47 (20\%) \\
Total samples & 232 \\
\midrule
\multicolumn{2}{l}{\textit{Training Time}} \\
Time per epoch & $\sim$1 second \\
Total time & $\sim$8 minutes \\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier

\subsection{PPO-Based RL Training}

\begin{table}[!h]
\caption{PPO Algorithm Hyperparameters}
\label{tab:ppo_hyperparams}
\centering
\small
\begin{tabular}{p{0.42\linewidth}p{0.48\linewidth}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
\multicolumn{2}{l}{\textit{Network Architecture}} \\
Policy network & [s\_dim, 256, 256, 2] \\
Value network & [s\_dim, 256, 256, 1] \\
State dimension & 23 \\
Action dimension & 2 ($\Delta K_p, \Delta K_d$) \\
Action range & $[-0.2, 0.2]$ \\
\midrule
\multicolumn{2}{l}{\textit{PPO Algorithm}} \\
Total timesteps & 1,000,000 \\
Parallel envs & 8 \\
Steps per env & 2,048 \\
Batch size & 256 \\
Mini-batch size & 256 \\
Epochs & 10 \\
Clip range $\epsilon$ & 0.2 \\
\midrule
\multicolumn{2}{l}{\textit{Learning Rates}} \\
Policy LR & $1 \times 10^{-4}$ \\
Value LR & $1 \times 10^{-4}$ \\
LR schedule & Constant \\
\midrule
\multicolumn{2}{l}{\textit{GAE \& Discount}} \\
Discount $\gamma$ & 0.99 \\
GAE $\lambda$ & 0.95 \\
\midrule
\multicolumn{2}{l}{\textit{Loss Coefficients}} \\
Value loss coef & 0.5 \\
Entropy coef & 0.02 \\
Max grad norm & 0.5 \\
\midrule
\multicolumn{2}{l}{\textit{Training Time}} \\
Wall-clock time & $\sim$10 minutes \\
FPS & $\sim$1,300 \\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier

\subsection{Data Augmentation and Optimization}

\begin{table}[!h]
\caption{Data Augmentation and PID Optimization}
\label{tab:augmentation_params}
\centering
\small
\begin{tabular}{p{0.45\linewidth}p{0.45\linewidth}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
\multicolumn{2}{l}{\textit{Property Perturbation}} \\
Mass range & $\pm 10\%$ \\
Inertia range & $\pm 10\%$ \\
Link length range & $\pm 5\%$ \\
Payload range & $[0, 2\times$ base$]$ \\
Virtual per robot & 100 \\
Total virtual & 300 \\
Total real & 3 \\
Before filtering & 303 \\
\midrule
\multicolumn{2}{l}{\textit{PID Optimization}} \\
DE population & 8 \\
DE iterations & 15 \\
DE mutation $F$ & 0.8 \\
DE crossover & 0.7 \\
Bounds & $K_p, K_d \in [0.1, 500]$ \\
 & $K_i \in [0, 1]$ \\
NM tolerance & $10^{-6}$ \\
Trajectory & 2000 steps (20s) \\
Time/sample & $\sim$3 min (23 cores) \\
Total time & $\sim$5 min \\
\midrule
\multicolumn{2}{l}{\textit{Data Filtering}} \\
Error threshold & $30°$ \\
Min per robot & 30 \\
Removed & 71 (23.4\%) \\
Final samples & 232 \\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier

\subsection{Reward Function and Environment}

\begin{table}[!h]
\caption{Reward Function and Environment}
\label{tab:reward_function}
\centering
\small
\begin{tabular}{p{0.38\linewidth}p{0.38\linewidth}p{0.14\linewidth}}
\toprule
\textbf{Component} & \textbf{Formula} & \textbf{Weight} \\
\midrule
Position error & $-\|q_t - q_{ref,t}\|_2$ & 1.0 \\
Velocity error & $-\|\dot{q}_t - \dot{q}_{ref,t}\|_2$ & 0.5 \\
Jerk penalty & $-\|\ddot{q}_t - \ddot{q}_{t-1}\|_2$ & 0.1 \\
PID change & $-\|\bm{\theta}_t - \bm{\theta}_{t-1}\|_2$ & 0.05 \\
Success bonus & +10 if $\|e_t\| < 5°$ & - \\
Failure penalty & -100 if unstable & - \\
\midrule
\multicolumn{3}{l}{\textit{Environment Settings}} \\
\multicolumn{2}{l}{Episode length} & 2000 steps \\
\multicolumn{2}{l}{Control frequency} & 100 Hz \\
\multicolumn{2}{l}{Simulator} & PyBullet 3.2.5 \\
\multicolumn{2}{l}{Physics timestep} & 0.01 s \\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier

\subsection{Computing Infrastructure}

\begin{table}[!h]
\caption{Computing Infrastructure}
\label{tab:computing}
\centering
\small
\begin{tabular}{p{0.4\linewidth}p{0.5\linewidth}}
\toprule
\textbf{Component} & \textbf{Specification} \\
\midrule
\multicolumn{2}{l}{\textit{Hardware}} \\
CPU & Intel i7-11800H (8c/16t) \\
GPU & NVIDIA RTX 3060 (6GB) \\
RAM & 16GB DDR4-3200 \\
OS & Ubuntu 20.04 LTS \\
\midrule
\multicolumn{2}{l}{\textit{Software}} \\
Python & 3.10.13 \\
PyTorch & 2.0.1 (CUDA 11.7) \\
Stable-Baselines3 & 2.0.0 \\
PyBullet & 3.2.5 \\
\midrule
\multicolumn{2}{l}{\textit{Training Time}} \\
Data augmentation & $\sim$5 min \\
PID optimization & $\sim$5 min \\
Meta-learning & $\sim$8 min \\
RL (per robot) & $\sim$2.5 hours \\
\textbf{Total pipeline} & \textbf{$\sim$3 hours} \\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier

\subsection{Multi-Seed Evaluation}

\begin{table}[!h]
\caption{Multi-Seed Evaluation Configuration}
\label{tab:multiseed}
\centering
\small
\begin{tabular}{p{0.42\linewidth}p{0.48\linewidth}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Seed range & 0-99 (100 different seeds) \\
Episodes per seed & 20 per disturbance scenario \\
Total episodes & 10,000 (100×5×20) \\
Representative seed & 51 (near-median performance) \\
Statistical metric & Mean±std across all seeds \\
\midrule
\multicolumn{2}{l}{\textit{Stochastic Factors Controlled by Seeds}} \\
\multicolumn{2}{l}{- Trajectory initialization randomness} \\
\multicolumn{2}{l}{- Disturbance timing and sequencing} \\
\multicolumn{2}{l}{- Environment noise and variations} \\
\multicolumn{2}{l}{- RL policy exploration randomness} \\
\bottomrule
\end{tabular}
\end{table}

\end{document}

