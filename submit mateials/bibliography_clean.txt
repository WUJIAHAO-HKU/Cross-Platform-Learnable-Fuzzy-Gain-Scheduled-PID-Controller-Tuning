\begin{thebibliography}{99}

\bibitem{astrom2006advanced}
K.~J. Åström, T.~Hägglund, Advanced PID Control, ISA-The Instrumentation, Systems, and Automation Society, 2006.



\bibitem{vilanova2012pid}
R.~Vilanova, A.~Visioli, PID Control in the Third Millennium: Lessons Learned and New Approaches, Springer-Verlag, London, UK, 2012.



\bibitem{johnson2021industrial}
C.~D. Johnson, M.~A. Franchek, Real-world challenges in industrial robot controller tuning: A case study analysis, IEEE Trans. Autom. Sci. Eng. 18~(3) (2021) 1456--1468.



\bibitem{gaing2004particle}
Z.-L. Gaing, A particle swarm optimization approach for optimum design of PID controller in AVR system, IEEE Trans. Energy Convers. 19~(2) (2004) 384--391.



\bibitem{berkenkamp2016safe}
F.~Berkenkamp, A.~P. Schoellig, A.~Krause, Safe controller optimization for quadrotors with Gaussian processes, in: Proc. IEEE ICRA, 2016, pp. 491--496.



\bibitem{lillicrap2015continuous}
T.~P. Lillicrap, J.~J. Hunt, A.~Pritzel, N.~Heess, T.~Erez, Y.~Tassa, D.~Silver, D.~Wierstra, Continuous control with deep reinforcement learning, arXiv preprint arXiv:1509.02971 (2015).



\bibitem{zhang2024disturbance}
Y.~Zhang, B.~Nie, Z.~Cao, Y.~Fu, Y.~Gao, Disturbance-aware adaptive compensation in hybrid force-position locomotion policy for legged robots, in: Proc. IEEE ICRA, 2024, arXiv:2506.00472.



\bibitem{trelea2003particle}
I.~C. Trelea, The particle swarm optimization algorithm: convergence analysis and parameter selection, Inf. Process. Lett. 85~(6) (2003) 317--325.



\bibitem{schulman2017proximal}
J.~Schulman, F.~Wolski, P.~Dhariwal, A.~Radford, O.~Klimov, Proximal policy optimization algorithms, arXiv preprint arXiv:1707.06347 (2017).



\bibitem{nagabandi2018neural}
A.~Nagabandi, G.~Kahn, R.~S. Fearing, S.~Levine, Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning, in: Proc. IEEE ICRA, 2018, pp. 7559--7566.



\bibitem{yu2021adaptive}
X.~Yu, P.~He, Z.~Wan, A.~Tsukada, An adaptive SAC-PID control method based on reinforcement learning for mobile robots, in: Proc. IEEE ICRA, 2021, arXiv:2103.10686.



\bibitem{jiang2022rl}
D.~Jiang, Z.~Li, Y.~Xia, Reinforcement learning based adaptive tracking control for continuum robots, J. System Simulation 34~(7) (2022) 1465--1475. (in Chinese)



\bibitem{pezzato2020active}
C.~Pezzato, R.~Ferrari, C.~Hernandez Corbato, A novel adaptive controller for robot manipulators based on active inference, IEEE Robotics Autom. Lett. 5~(2) (2020) 2973--2980.



\bibitem{hospedales2021meta}
T.~Hospedales, A.~Antoniou, P.~Micaelli, A.~Storkey, Meta-learning in neural networks: A survey, IEEE Trans. Pattern Anal. Mach. Intell. 44~(9) (2022) 5149--5169.



\bibitem{finn2017model}
C.~Finn, P.~Abbeel, S.~Levine, Model-agnostic meta-learning for fast adaptation of deep networks, in: Proc. ICML, 2017, pp. 1126--1135.



\bibitem{finn2017one}
C.~Finn, T.~Yu, T.~Zhang, P.~Abbeel, S.~Levine, One-shot visual imitation learning via meta-learning, in: Proc. CoRL, 2017, pp. 357--368.



\bibitem{yu2020meta}
W.~Yu, C.~K. Liu, G.~Turk, Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning, in: Proc. CoRL, 2020, pp. 1094--1100.



\bibitem{he2024self}
W.~He, Y.~Hu, Y.~Guan, M.~Xue, Self-supervised meta-learning for all-layer DNN-based adaptive control with stability guarantees, in: Proc. IEEE CDC, 2024, arXiv:2410.07575.



\bibitem{tobin2017domain}
J.~Tobin, R.~Fong, A.~Ray, J.~Schneider, W.~Zaremba, P.~Abbeel, Domain randomization for transferring deep neural networks from simulation to the real world, in: Proc. IEEE/RSJ IROS, 2017, pp. 23--30.



\bibitem{peng2018sim}
X.~B. Peng, M.~Andrychowicz, W.~Zaremba, P.~Abbeel, Sim-to-real transfer of robotic control with dynamics randomization, in: Proc. IEEE ICRA, 2018, pp. 3803--3810.



\bibitem{kumar2021rma}
A.~Kumar, Z.~Fu, D.~Pathak, J.~Malik, RMA: Rapid motor adaptation for legged robots, in: Proc. CoRL, 2021, pp. 1034--1045.



\bibitem{okamoto2021robust}
S.~Okamoto, S.~Nagano, M.~Kojima, Robust fault-tolerant control of quadruped robots using adaptive curriculum dynamic randomization, IEEE Access 9 (2021) 150385--150396.



\bibitem{shorten2019survey}
C.~Shorten, T.~M. Khoshgoftaar, A survey on image data augmentation for deep learning, J. Big Data 6~(1) (2019) 1--48.



\bibitem{todorov2012mujoco}
E.~Todorov, T.~Erez, Y.~Tassa, MuJoCo: A physics engine for model-based control, in: Proc. IEEE/RSJ IROS, 2012, pp. 5026--5033.



\bibitem{storn1997differential}
R.~Storn, K.~Price, Differential evolution -- A simple and efficient heuristic for global optimization over continuous spaces, J. Global Optim. 11~(4) (1997) 341--359.



\bibitem{nelder1965simplex}
J.~A. Nelder, R.~Mead, A simplex method for function minimization, Comput. J. 7~(4) (1965) 308--313.



\bibitem{coumans2016pybullet}
E.~Coumans, Y.~Bai, PyBullet, a Python module for physics simulation for games, robotics and machine learning, 2016. [Online]. Available: http://pybullet.org



\bibitem{iso9283}
International Organization for Standardization, ISO 9283:1998 Manipulating Industrial Robots—Performance Criteria and Related Test Methods, ISO Standards, Geneva, Switzerland, 1998.



\bibitem{cho2019identification}
J.~Cho, S.~Kim, Parameter identification and model validation of industrial robot manipulators under manufacturing tolerances, Robotica 37~(10) (2019) 1656--1672.



\bibitem{lee2022parameter}
S.~Lee, H.~Park, J.~Kim, Real-world parameter uncertainty quantification in collaborative robots: An experimental study, IEEE Robotics Autom. Lett. 7~(4) (2022) 9847--9854.



\bibitem{collins2021review}
J.~Collins, S.~Chand, A.~Vanderkop, D.~Howard, A review of physics simulators for robotic applications, IEEE Access 9 (2021) 51416--51431.



\bibitem{tan2018sim}
J.~Tan, T.~Zhang, E.~Coumans, et al., Sim-to-real: Learning agile locomotion for quadruped robots, in: Proc. Robotics: Science and Systems (RSS), 2018.



\bibitem{margolis2024rapid}
G.~B. Margolis, T.~Yang, K.~Paigwar, X.~Chen, P.~Agrawal, Rapid locomotion via reinforcement learning, in: Proc. Robotics: Science and Systems (RSS), 2024, arXiv:2404.01063.



\bibitem{frankaemika2021benchmark}
Franka Emika GmbH, Franka Panda Performance Benchmarks: Position Control Accuracy in Industrial Settings, Technical Report FE-2021-03, Munich, Germany, 2021.



\bibitem{ott2017unified}
C.~Ott, A.~Dietrich, A.~Albu-Schäffer, Unified impedance and admittance control, in: Proc. IEEE ICRA, 2017, pp. 554--560.



\bibitem{zhao2020sim2real}
W.~Zhao, J.~P. Queralta, T.~Westerlund, Sim-to-real transfer in deep reinforcement learning for robotics: A survey, in: Proc. IEEE SSCI, 2020, pp. 737--744.



\bibitem{openai2020learning}
OpenAI et al., Learning dexterous in-hand manipulation, Int. J. Robotics Res. 39~(1) (2020) 3--20.



\bibitem{berkenkamp2021safe}
F.~Berkenkamp, A.~P. Schoellig, Safe exploration in reinforcement learning: Theory and applications in robotics, in: Proc. European Control Conference (ECC), 2021, pp. 1--19.



\bibitem{andrychowicz2020learning}
M.~Andrychowicz, B.~Baker, M.~Chociej, et al., Learning dexterous in-hand manipulation, Int. J. Robotics Res. 39~(1) (2020) 3--20.







% ============================================================================
% WARNING: The following 14 bibitems are NOT cited in the main text:
% These should be removed unless intentionally kept
% ============================================================================

% UNCITED: accenture2023consulting
% UNCITED: agile2024manufacturing
% UNCITED: armbrust2010cloud
% UNCITED: aws2023economics
% UNCITED: bcg2023robotics
% UNCITED: deloitte2023manufacturing
% UNCITED: ieee2023salary
% UNCITED: ifr2023worldrobotics
% UNCITED: lean2023manufacturing
% UNCITED: mckinsey2024automation
% UNCITED: mit2024deployment
% UNCITED: nist2023manufacturing
% UNCITED: robotics2024smesurvey
% UNCITED: upwork2024engineering

\end{thebibliography}
