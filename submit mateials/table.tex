\documentclass[11pt,a4paper]{article}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{bm}
\usepackage[table]{xcolor}
\usepackage{geometry}
\geometry{
    left=2.5cm,    % 左边距
    right=2.5cm,   % 右边距
    top=2cm,     % 上边距
    bottom=2cm   % 下边距
}
% Define custom column types
\newcolumntype{L}{l}

\title{All Tables from Meta-RL PID Control Manuscript}
\author{}
\date{}

\begin{document}

\maketitle

\section*{Summary}

This document contains all tables extracted from the manuscript. Tables are organized by their appearance in the paper:

\begin{itemize}
    \item \textbf{Main Text Tables (9):} Core results and comparisons
    \begin{itemize}
        \item Table 1: Full Lifecycle Cost Comparison
        \item Table 2: Industrial Viability Analysis
        \item Table 3: Baseline Design Summary
        \item Table 4: Performance on Franka Panda
        \item Table 5: Performance on Laikago
        \item Table 6: Per-Joint Tracking Error Comparison
        \item Table 7: Robustness Analysis
        \item Table 8: Ablation - Data Augmentation Impact
        \item Table 9: Method Comparison - Proposed vs Traditional
    \end{itemize}
    \item \textbf{Appendix Tables (6):} Hyperparameters and configuration
    \item \textbf{Nomenclature Tables (2):} Acronyms and mathematical symbols
\end{itemize}

\textbf{Total Tables: 17}

\textbf{Note:} All tables include "Source: Authors own work" attribution as per journal submission requirements.

% ===========================================================================
% MAIN TEXT TABLES
% ===========================================================================

\section*{MAIN TEXT TABLES}

% ===========================================================================
% TABLE 1: Full Lifecycle Cost Comparison
% ===========================================================================

\section*{Table 1: Full Lifecycle Cost Comparison (USD, Per-Robot Basis)}

\small
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}>{\centering\arraybackslash}m{2.2cm}>{\centering\arraybackslash}m{1.8cm}>{\centering\arraybackslash}m{1.8cm}>{\centering\arraybackslash}m{1.5cm}>{\centering\arraybackslash}m{1.5cm}>{\centering\arraybackslash}m{1.8cm}>{\centering\arraybackslash}m{2.0cm}@{}}
\toprule
\textbf{Method} & \textbf{Setup} & \textbf{Deploy} & \textbf{Adapt} & \textbf{Maint.} & \textbf{Total (1)} & \textbf{Total (100)} \\
\midrule
\makecell{\textbf{Manual} \\ (40-120h @\$150/h)} & \$0 & \makecell{\$6-36K \\ (initial)} & \makecell{\$3-12K \\ (per dist.)} & \makecell{\$1.2K/yr \\ (retune)} & \$10-49K & \makecell{\textbf{\$1.1-4.9M}} \\
\makecell{\textbf{Heuristic} \\ (Z-N)} & \$0 & \makecell{\$0.6-2.4K \\ (4-8h)} & \makecell{\$2.4-9.6K \\ (perf. loss)} & \makecell{\$0.8K/yr \\ (adjust)} & \$3.8-13K & \makecell{\$0.4-1.3M} \\
\textbf{Optim.} (license) & \$5K & \makecell{\$1.2-7.2K \\ (8-24h)} & \$0 & \makecell{\$0.6K/yr} & \$6.8-13K & \makecell{\$0.7-1.3M} \\
\makecell{\textbf{Pure RL} \\ (GPU+infra)} & \makecell{\$50-200K} & \makecell{\$5-20K \\ (10-50h GPU)} & \$0 & \makecell{\$3K/yr} & \$58-223K & \makecell{\textbf{\$5.8-22M}} \\
\makecell{\textbf{Meta-L.} \\ (50-200 bots)} & \textbf{\$5-20M} & \makecell{\$0.75-3K \\ (5-10h)} & \$0 & \makecell{\$1.5K/yr} & \textbf{\$5-20M} & \textbf{\$5.2-20M} \\
\makecell{\textbf{Transfer} \\ (sim infra)} & \$10-50K & \makecell{\$3-12K \\ (20-40h)} & \makecell{\$1.5-6K \\ (s2r gap)} & \makecell{\$1K/yr} & \$15-69K & \makecell{\$1.7-6.9M} \\
\makecell{\textcolor{green!50!black}{\textbf{Ours}} \\ \textcolor{green!50!black}{(Phys. Meta-RL)}} & \textcolor{green!50!black}{\makecell{\textbf{\$0} \\ (sim)}} & \textcolor{green!50!black}{\makecell{\textbf{\$25} \\ (10min)}} & \textcolor{green!50!black}{\makecell{\textbf{\$0} \\ (online)}} & \textcolor{green!50!black}{\makecell{\textbf{\$0} \\ (auto)}} & \textcolor{green!50!black}{\textbf{\$25}} & \textcolor{green!50!black}{\makecell{\textbf{\$2.5K} \\ (99.5\%)}} \\
\bottomrule
\end{tabular*}

\vspace{0.3cm}
\noindent
\textbf{Source:} Authors own work.

% ===========================================================================
% TABLE 2: Industrial Viability Analysis
% ===========================================================================

\section*{Table 2: Industrial Viability Analysis - Prior Methods vs. Our Approach}

\small
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}>{\centering\arraybackslash}m{1.8cm}>{\centering\arraybackslash}m{1.5cm}>{\centering\arraybackslash}m{1.5cm}>{\centering\arraybackslash}m{1.0cm}>{\centering\arraybackslash}m{1.2cm}>{\centering\arraybackslash}m{1.0cm}>{\centering\arraybackslash}m{3.2cm}@{}}
\toprule
\textbf{Method} & \textbf{Capital Cost} & \textbf{Time Cost} & \textbf{Expert} & \textbf{Cross-Plat.} & \textbf{Online} & \textbf{Why It Fails} \\
\midrule
\textbf{Manual Tuning} & \$0 & 40-120 hrs (\$6-36K) & Yes & No & No & Expert scarcity ($<$2\%); Non-transferable \\
\textbf{Heuristic} (Z-N) & \$0 & 4-8 hrs (\$0.6-2.4K) & Mod. & No & No & 30-50\% perf. loss; Per-platform tune \\
\textbf{Optimization} & \$0 & 8-24 hrs (\$1.2-7.2K) & Low & No & No & Expensive compute; Repeat per platform \\
\textbf{Pure RL} & \$50-200K (sim) & 10-50 hrs (GPU) & Low & No & Yes & 10$^6$-10$^8$ samples; Prohibitive cost \\
\textbf{Meta-Learn.} & \textbf{\$5-20M} (50-200 bots) & 5-10 hrs & Low & Yes & No & \textbf{Capital barrier} (98\% excluded) \\
\textbf{Transfer} & \$10-50K (sim) & 20-40 hrs & Mod. & Ltd. & No & 20-40\% sim-to-real loss; Expensive tune \\
\textbf{Adaptive} & \$0 & 16-60 hrs (\$2.4-18K) & Yes & No & Yes & Expert initialization; Perpetuates cycle \\
\textcolor{green!50!black}{\textbf{Ours} (Meta-RL+Phys.)} & \textcolor{green!50!black}{\textbf{\$0} (3 sim)} & \textcolor{green!50!black}{\textbf{10 min} (\$25)} & \textcolor{green!50!black}{\textbf{No}} & \textcolor{green!50!black}{\textbf{Yes}} & \textcolor{green!50!black}{\textbf{Yes}} & \textcolor{green!50!black}{\textbf{Removes all barriers:} Virtual synth., zero experts} \\
\bottomrule
\end{tabular*}

\vspace{0.3cm}
\noindent
\textbf{Source:} Authors own work.

% ===========================================================================
% TABLE 3: Baseline Design Summary
% ===========================================================================

\section*{Table 3: Baseline Design Summary}

\small
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}>{\centering\arraybackslash}m{1.8cm}>{\centering\arraybackslash}m{2.2cm}>{\centering\arraybackslash}m{2.5cm}@{}}
\toprule
\textbf{Baseline} & \textbf{Deploy Time} & \textbf{Key Characteristic} \\
\midrule
Meta-PID & 0.8 ms & Instant zero-shot, no adaptation \\
Meta-PID+RL & 10 min & Online refinement, training cost \\
Heuristic (Z-N) & 40-120 hrs & Expert dependent, no transfer \\
Optimized (DE) & 30-60 min & High accuracy, no generalization \\
\bottomrule
\end{tabular*}

\vspace{0.3cm}
\noindent
\textbf{Source:} Authors own work.

% ===========================================================================
% TABLE 4: Performance on Franka Panda (9-DOF)
% ===========================================================================

\section*{Table 4: Performance on Franka Panda (9-DOF)}

\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}LLLL@{}}
\toprule
\textbf{Metric} & \textbf{Meta-PID} & \textbf{Meta-PID+RL} & \textbf{Improv.} \\
\midrule
MAE (°) & 7.51 & \textbf{6.26} & +16.6\% \\
RMSE (°) & 29.32 & \textbf{25.45} & +13.2\% \\
Max Error (°) & 48.49 & \textbf{42.12} & +13.1\% \\
Std Dev (°) & 4.94 & \textbf{4.40} & +10.9\% \\
\bottomrule
\end{tabular*}

\vspace{0.3cm}
\noindent
\textbf{Source:} Authors own work.

% ===========================================================================
% TABLE 5: Performance on Laikago (12-DOF)
% ===========================================================================

\section*{Table 5: Performance on Laikago (12-DOF)}

\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}LLLL@{}}
\toprule
\textbf{Metric} & \textbf{Meta-PID} & \textbf{Meta-PID+RL} & \textbf{Improv.} \\
\midrule
MAE (°) & 5.91 & \textbf{5.79} & +2.1\% \\
RMSE (°) & 29.70 & \textbf{29.29} & +1.4\% \\
Max Error (°) & 53.09 & \textbf{50.44} & +5.0\% \\
Std Dev (°) & 5.25 & \textbf{5.18} & +1.3\% \\
\bottomrule
\end{tabular*}

\vspace{0.3cm}
\noindent
\textbf{Source:} Authors own work.

% ===========================================================================
% TABLE 6: Per-Joint Tracking Error Comparison Across Platforms
% ===========================================================================

\section*{Table 6: Per-Joint Tracking Error Comparison Across Platforms}

\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}lllll@{}}
\toprule
\textbf{Robot} & \textbf{Joint} & \textbf{Pure Meta-PID (°)} & \textbf{Meta-PID+RL (°)} & \textbf{Improv.} \\
\midrule
Franka Panda    & J1     &   2.57 &   2.26 & +12.2\% \\
                & J2     &  12.36 &   2.42 & \textbf{+80.4\%} \\
                & J3     &   4.10 &   3.87 &  +5.7\% \\
                & J4     &   6.78 &   6.49 &  +4.3\% \\
                & J5     &   5.41 &   5.32 &  +1.6\% \\
                & J6     &   4.31 &   4.19 &  +2.8\% \\
                & J7     &  11.45 &  11.26 &  +1.6\% \\
                & J8     &  10.23 &  10.19 &  +0.3\% \\
                & J9     &  10.36 &  10.33 &  +0.3\% \\
\midrule
\textit{Franka Panda Avg} & &   7.51 &   6.26 & +16.6\% \\
\midrule
Laikago         & J1     &   1.38 &   1.52 &  -9.6\% \\
                & J2     &   6.16 &   5.96 &  +3.3\% \\
                & J3     &  10.45 &  10.34 &  +1.0\% \\
                & J4     &   1.36 &   1.45 &  -6.8\% \\
                & J5     &   5.70 &   5.96 &  -4.5\% \\
                & J6     &  10.54 &  10.33 &  +2.0\% \\
                & J7     &   1.36 &   1.41 &  -3.1\% \\
                & J8     &   5.35 &   5.86 &  -9.6\% \\
                & J9     &  10.44 &  10.36 &  +0.8\% \\
                & J10    &   1.35 &   1.44 &  -6.7\% \\
                & J11    &   6.41 &   5.92 &  +7.7\% \\
                & J12    &  10.44 &  10.39 &  +0.5\% \\
\midrule
\textit{Laikago Avg} & &   5.91 &   5.79 &  +2.1\% \\
\bottomrule
\end{tabular*}

\vspace{0.3cm}
\noindent
\textbf{Source:} Authors own work.

% ===========================================================================
% TABLE 7: Robustness Analysis (Franka Panda)
% ===========================================================================

\section*{Table 7: Robustness Analysis (Franka Panda, MAE in degrees, Representative Seed 51, 20 Episodes)}

\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}LLLL@{}}
\toprule
\textbf{Disturbance} & \textbf{Meta-PID} & \textbf{Meta-PID+RL} & \textbf{Improv.} \\
\midrule
No Disturbance & 7.51 & \textbf{6.26} & +16.6\% \\
Random Force & 25.77 & \textbf{25.01} & +2.9\% \\
Payload Var. & 67.12 & \textbf{61.68} & +8.1\% \\
\textbf{Param. Uncert.} & 35.90 & \textbf{29.01} & \textbf{+19.2\%} \\
Mixed Dist. & 88.00 & \textbf{82.37} & +6.4\% \\
\midrule
\textit{Average} & \textit{49.09} & \textit{44.59} & \textit{+10.0\%} \\
\bottomrule
\end{tabular*}

\vspace{0.3cm}
\noindent
\textbf{Source:} Authors own work.

% ===========================================================================
% TABLE 8: Ablation - Data Augmentation Impact
% ===========================================================================

\section*{Table 8: Ablation - Data Augmentation Impact}

\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}LLL@{}}
\toprule
\textbf{Training Data} & \textbf{Samples} & \textbf{Prediction Error (\%)} \\
\midrule
Base robots only & 3 & 31.2 \\
+ Augmentation & 303 & 3.33 \\
\bottomrule
\end{tabular*}

\vspace{0.3cm}
\noindent
\textbf{Source:} Authors own work.

% ===========================================================================
% TABLE 9: Method Comparison - Proposed vs Traditional
% ===========================================================================

\section*{Table 9: Method Comparison - Proposed Approach vs. Traditional Methods}

\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}LLL@{}}
\toprule
\textbf{Aspect} & \textbf{Traditional Methods} & \textbf{Our Method} \\
\midrule
Tuning Time & Hours to days & \textbf{10 minutes} \\
Expert Required & Yes (manual tuning) & \textbf{No (automated)} \\
Cross-Platform & Per-robot tuning & \textbf{Yes (9-12 DOF)} \\
Online Adaptation & No & \textbf{Yes (+19.2\%)} \\
Sample Efficiency & N/A (manual) & \textbf{1M steps} \\
Disturbance Handling & Fixed parameters & \textbf{Adaptive} \\
\bottomrule
\end{tabular*}

\vspace{0.3cm}
\noindent
\textbf{Source:} Authors own work.

% ===========================================================================
% APPENDIX TABLES
% ===========================================================================

\section*{APPENDIX TABLES}

% ===========================================================================
% TABLE 10: Meta-Learning Network Hyperparameters
% ===========================================================================

\section*{Table 10: Meta-Learning Network Hyperparameters}

\noindent
\label{tab:meta_hyperparams}
\centering
\small
\begin{tabular}{@{}p{0.42\linewidth}p{0.48\linewidth}@{}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
\multicolumn{2}{@{}l}{\textit{Network Architecture}} \\
Input dimension & 10 \\
Encoder layers & 256 + 256 + LayerNorm \\
Hidden layer & 128 + LayerNorm \\
Output dimension & 7 \\
Output activation & Sigmoid \\
\midrule
\multicolumn{2}{@{}l}{\textit{Training Configuration}} \\
Optimizer & Adam \\
Learning rate & 0.001 \\
Weight decay & $10^{-5}$ \\
Batch size & 32 \\
Max epochs & 500 \\
Early stopping & 50 epochs \\
Loss function & Weighted MSE \\
\midrule
\multicolumn{2}{@{}l}{\textit{Data Split}} \\
Training samples & 185 (80\%) \\
Validation samples & 47 (20\%) \\
Total samples & 232 \\
\midrule
\multicolumn{2}{@{}l}{\textit{Training Time}} \\
Time per epoch & $\sim$1 second \\
Total time & $\sim$8 minutes \\
\bottomrule
\end{tabular}

% ===========================================================================
% TABLE 11: PPO Algorithm Hyperparameters
% ===========================================================================

\section*{Table 11: PPO Algorithm Hyperparameters}

\noindent
\label{tab:ppo_hyperparams}
\centering
\small
\begin{tabular}{@{}p{0.42\linewidth}p{0.48\linewidth}@{}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
\multicolumn{2}{@{}l}{\textit{Network Architecture}} \\
Policy network & [s\_dim, 256, 256, 2] \\
Value network & [s\_dim, 256, 256, 1] \\
State dimension & 23 \\
Action dimension & 2 ($\Delta K_p, \Delta K_d$) \\
Action range & $[-0.2, 0.2]$ \\
\midrule
\multicolumn{2}{@{}l}{\textit{PPO Algorithm}} \\
Total timesteps & 1,000,000 \\
Parallel envs & 8 \\
Steps per env & 2,048 \\
Batch size & 256 \\
Mini-batch size & 256 \\
Epochs & 10 \\
Clip range $\epsilon$ & 0.2 \\
\midrule
\multicolumn{2}{@{}l}{\textit{Learning Rates}} \\
Policy LR & $1 \times 10^{-4}$ \\
Value LR & $1 \times 10^{-4}$ \\
LR schedule & Constant \\
\midrule
\multicolumn{2}{@{}l}{\textit{GAE \& Discount}} \\
Discount $\gamma$ & 0.99 \\
GAE $\lambda$ & 0.95 \\
\midrule
\multicolumn{2}{@{}l}{\textit{Loss Coefficients}} \\
Value loss coef & 0.5 \\
Entropy coef & 0.02 \\
Max grad norm & 0.5 \\
\midrule
\multicolumn{2}{@{}l}{\textit{Training Time}} \\
Wall-clock time & $\sim$10 minutes \\
FPS & $\sim$1,300 \\
\bottomrule
\end{tabular}

% ===========================================================================
% TABLE 3: Data Augmentation and PID Optimization
% ===========================================================================

\section*{Table 12: Data Augmentation and PID Optimization}

\noindent
\label{tab:augmentation_params}
\centering
\small
\begin{tabular}{@{}p{0.45\linewidth}p{0.45\linewidth}@{}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
\multicolumn{2}{@{}l}{\textit{Property Perturbation}} \\
Mass range & $\pm 10\%$ \\
Inertia range & $\pm 10\%$ \\
Link length range & $\pm 5\%$ \\
Payload range & $[0, 2\times$ base$]$ \\
Virtual per robot & 100 \\
Total virtual & 300 \\
Total real & 3 \\
Before filtering & 303 \\
\midrule
\multicolumn{2}{@{}l}{\textit{PID Optimization}} \\
DE population & 8 \\
DE iterations & 15 \\
DE mutation $F$ & 0.8 \\
DE crossover & 0.7 \\
Bounds & $K_p, K_d \in [0.1, 500]$ \\
 & $K_i \in [0, 1]$ \\
NM tolerance & $10^{-6}$ \\
Trajectory & 2000 steps (20s) \\
Time/sample & $\sim$3 min (23 cores) \\
Total time & $\sim$5 min \\
\midrule
\multicolumn{2}{@{}l}{\textit{Data Filtering}} \\
Error threshold & 30$^\circ$ \\
Min per robot & 30 \\
Removed & 71 (23.4\%) \\
Final samples & 232 \\
\bottomrule
\end{tabular}

% ===========================================================================
% TABLE 4: Reward Function and Environment
% ===========================================================================

\section*{Table 13: Reward Function and Environment}

\noindent
\label{tab:reward_function}
\centering
\small
\begin{tabular}{@{}p{0.38\linewidth}p{0.38\linewidth}p{0.14\linewidth}@{}}
\toprule
\textbf{Component} & \textbf{Formula} & \textbf{Weight} \\
\midrule
Position error & $-\|q_t - q_{ref,t}\|_2$ & 1.0 \\
Velocity error & $-\|\dot{q}_t - \dot{q}_{ref,t}\|_2$ & 0.5 \\
Jerk penalty & $-\|\ddot{q}_t - \ddot{q}_{t-1}\|_2$ & 0.1 \\
PID change & $-\|\bm{\theta}_t - \bm{\theta}_{t-1}\|_2$ & 0.05 \\
Success bonus & +10 if $\|e_t\| < 5^\circ$ & - \\
Failure penalty & -100 if unstable & - \\
\midrule
\multicolumn{3}{@{}l}{\textit{Environment Settings}} \\
\multicolumn{2}{@{}l}{Episode length} & 2000 steps \\
\multicolumn{2}{@{}l}{Control frequency} & 100 Hz \\
\multicolumn{2}{@{}l}{Simulator} & PyBullet 3.2.5 \\
\multicolumn{2}{@{}l}{Physics timestep} & 0.01 s \\
\bottomrule
\end{tabular}

% ===========================================================================
% TABLE 5: Computing Infrastructure
% ===========================================================================

\section*{Table 14: Computing Infrastructure}

\noindent
\label{tab:computing}
\centering
\small
\begin{tabular}{@{}p{0.4\linewidth}p{0.5\linewidth}@{}}
\toprule
\textbf{Component} & \textbf{Specification} \\
\midrule
\multicolumn{2}{@{}l}{\textit{Hardware}} \\
CPU & Intel i7-11800H (8c/16t) \\
GPU & NVIDIA RTX 3060 (6GB) \\
RAM & 16GB DDR4-3200 \\
OS & Ubuntu 20.04 LTS \\
\midrule
\multicolumn{2}{@{}l}{\textit{Software}} \\
Python & 3.10.13 \\
PyTorch & 2.0.1 (CUDA 11.7) \\
Stable-Baselines3 & 2.0.0 \\
PyBullet & 3.2.5 \\
\midrule
\multicolumn{2}{@{}l}{\textit{Training Time}} \\
Data augmentation & $\sim$5 min \\
PID optimization & $\sim$5 min \\
Meta-learning & $\sim$8 min \\
RL (per robot) & $\sim$2.5 hours \\
\textbf{Total pipeline} & \textbf{$\sim$3 hours} \\
\bottomrule
\end{tabular}

% ===========================================================================
% TABLE 6: Multi-Seed Evaluation Configuration
% ===========================================================================

\section*{Table 15: Multi-Seed Evaluation Configuration}

\noindent
\centering
\small
\begin{tabular}{@{}p{0.42\linewidth}p{0.48\linewidth}@{}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Seed range & 0-99 (100 different seeds) \\
Episodes per seed & 20 per disturbance scenario \\
Total episodes & 10,000 (100×5×20) \\
Representative seed & 51 (near-median performance) \\
Statistical metric & Mean±std across all seeds \\
\midrule
\multicolumn{2}{@{}l}{\textit{Stochastic Factors Controlled by Seeds}} \\
\multicolumn{2}{@{}l}{- Trajectory initialization randomness} \\
\multicolumn{2}{@{}l}{- Disturbance timing and sequencing} \\
\multicolumn{2}{@{}l}{- Environment noise and variations} \\
\multicolumn{2}{@{}l}{- RL policy exploration randomness} \\
\bottomrule
\end{tabular}

% ===========================================================================
% NOMENCLATURE TABLE: Acronyms
% ===========================================================================

% ===========================================================================
% NOMENCLATURE TABLES
% ===========================================================================

\section*{NOMENCLATURE TABLES}

% ===========================================================================
% TABLE 16: Nomenclature - Acronyms
% ===========================================================================

\section*{Table 16: Nomenclature - Acronyms}

\begin{tabular}{@{}p{0.25\linewidth}p{0.65\linewidth}@{}}
\toprule
\textbf{Acronym} & \textbf{Description} \\
\midrule
PID & Proportional-Integral-Derivative \\
RL & Reinforcement Learning \\
PPO & Proximal Policy Optimization \\
DE & Differential Evolution \\
MAML & Model-Agnostic Meta-Learning \\
MAE & Mean Absolute Error \\
RMSE & Root Mean Square Error \\
NMAE & Normalized Mean Absolute Error \\
DOF & Degrees of Freedom \\
MLP & Multi-Layer Perceptron \\
\bottomrule
\end{tabular}

% ===========================================================================
% TABLE 17: Nomenclature - Mathematical Symbols
% ===========================================================================

\section*{Table 17: Nomenclature - Mathematical Symbols}

\begin{tabular}{@{}p{0.20\linewidth}p{0.50\linewidth}p{0.20\linewidth}@{}}
\toprule
\textbf{Symbol} & \textbf{Description} & \textbf{Dim/Value} \\
\midrule
\multicolumn{3}{@{}l}{\textit{Robot Features \& Network Architecture}} \\
$\mathbf{f}$ & Robot feature vector & $\mathbb{R}^{10}$ \\
$n_{dof}$ & Number of degrees of freedom & - \\
$\mathbf{h}_1, \mathbf{h}_2$ & Encoder layer outputs & $\mathbb{R}^{256}$ \\
$\mathbf{h}_{hidden}$ & Hidden layer output & $\mathbb{R}^{128}$ \\
$W_1, W_2, W_3$ & Weight matrices & - \\
$\sigma$ & Sigmoid activation & - \\[0.2cm]
\multicolumn{3}{@{}l}{\textit{PID Control Parameters}} \\
$K_p, K_i, K_d$ & PID gain parameters & - \\
$\hat{K}_p, \hat{K}_i, \hat{K}_d$ & Predicted PID parameters & $[0,1]^n$ \\
$\bm{\theta}$ & PID parameter vector & $\mathbb{R}^{3n}$ \\
$\bm{\theta}_v^*$ & Ground-truth optimal PID & - \\
$\hat{\bm{\theta}}_v$ & Predicted PID parameters & - \\[0.2cm]
\multicolumn{3}{@{}l}{\textit{Control \& Trajectory}} \\
$q(t)$ & Joint position vector & rad \\
$\dot{q}(t)$ & Joint velocity vector & rad/s \\
$q_{ref}(t)$ & Reference trajectory & rad \\
$e(t)$ & Tracking error & rad \\
$u(t)$ & Control torque & N$\cdot$m \\
$n$ & Number of joints & - \\[0.2cm]
\multicolumn{3}{@{}l}{\textit{Loss Functions \& Optimization}} \\
$\mathcal{L}_{meta}$ & Meta-learning loss & - \\
$\mathcal{L}_v(\theta)$ & Trajectory tracking error & rad \\
$w_v$ & Sample weight & - \\
$N$ & Number of samples & 303 \\
$\theta^*_{global}$ & Optimal PID from DE & - \\
$\theta^*_v$ & Final optimal PID & - \\
$T$ & Trajectory length & 2000 \\[0.2cm]
\multicolumn{3}{@{}l}{\textit{RL Components}} \\
$\mathbf{s}_t$ & State observation & - \\
$\mathbf{a}_t$ & RL action & $[-0.2,0.2]^2$ \\
$r_t$ & Reward signal & $[-100,10]$ \\
$\gamma$ & Discount factor & 0.99 \\
$\lambda$ & GAE parameter & 0.95 \\
\bottomrule
\end{tabular}

\section*{List of All Tables in This Document}

\subsection*{Main Text Tables (Tables 1-9)}
\begin{enumerate}
    \item Full Lifecycle Cost Comparison (USD, Per-Robot Basis)
    \item Industrial Viability Analysis - Prior Methods vs. Our Approach
    \item Baseline Design Summary
    \item Performance on Franka Panda (9-DOF)
    \item Performance on Laikago (12-DOF)
    \item Per-Joint Tracking Error Comparison Across Platforms
    \item Robustness Analysis (Franka Panda, MAE in degrees)
    \item Ablation - Data Augmentation Impact
    \item Method Comparison - Proposed Approach vs. Traditional Methods
\end{enumerate}

\subsection*{Appendix Tables (Tables 10-15)}
\begin{enumerate}
    \setcounter{enumi}{9}
    \item Meta-Learning Network Hyperparameters (Appendix A.1)
    \item PPO Algorithm Hyperparameters (Appendix A.2)
    \item Data Augmentation and PID Optimization (Appendix A.3)
    \item Reward Function and Environment (Appendix A.4)
    \item Computing Infrastructure (Appendix A.5)
    \item Multi-Seed Evaluation Configuration (Appendix A.6)
\end{enumerate}

\subsection*{Nomenclature Tables (Tables 16-17)}
\begin{enumerate}
    \setcounter{enumi}{15}
    \item Nomenclature - Acronyms
    \item Nomenclature - Mathematical Symbols
\end{enumerate}

\vspace{0.5cm}
\noindent
\textbf{Note:} All tables preserve original LaTeX formatting from the manuscript, including caption labels, mathematical notation, and source attribution.

\end{document}
